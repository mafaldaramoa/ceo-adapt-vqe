{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cd88d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from copy import deepcopy\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt; plt.rcParams.update({\"font.family\": \"serif\"})\n",
    "\n",
    "import pyscf\n",
    "import pyscf.cc\n",
    "import pyscf.mcscf\n",
    "\n",
    "# To get molecular geometries.\n",
    "import openfermion as of\n",
    "from openfermion import MolecularData\n",
    "from openfermionpyscf import run_pyscf\n",
    "\n",
    "import qiskit\n",
    "from qiskit import QuantumCircuit, QuantumRegister\n",
    "from qiskit.primitives import BitArray\n",
    "from qiskit_aer import AerSimulator  # For MPS Simulator.\n",
    "from qiskit.primitives import StatevectorEstimator\n",
    "\n",
    "import ffsim\n",
    "\n",
    "# To run on hardware.\n",
    "import qiskit_ibm_runtime\n",
    "from qiskit_ibm_runtime import SamplerV2 as Sampler\n",
    "\n",
    "from functools import partial, reduce\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# from qiskit_addon_sqd.fermion import SCIResult, diagonalize_fermionic_hamiltonian, solve_sci_batch\n",
    "from qiskit_addon_sqd.qubit import solve_qubit, sort_and_remove_duplicates\n",
    "\n",
    "from adaptvqe.pools import DVG_CEO, FullPauliPool, TiledPauliPool\n",
    "from adaptvqe.convert import cirq_pauli_sum_to_qiskit_pauli_op\n",
    "from adaptvqe.hamiltonians import XXZHamiltonian\n",
    "from adaptvqe.algorithms.adapt_vqe import LinAlgAdapt, TensorNetAdapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "268707c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/.venv/adapt/lib/python3.13/site-packages/qiskit_ibm_runtime/fake_provider/backends/nighthawk/fake_nighthawk.py:76: UserWarning: Properties of fake_nighthawk are not intended to represent typical nighthawk error values.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ibm_computer: str = \"ibm_fez\"\n",
    "\n",
    "service = qiskit_ibm_runtime.QiskitRuntimeService(channel=\"local\")\n",
    "computer = service.backend()\n",
    "sampler = Sampler(computer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09186101",
   "metadata": {},
   "source": [
    "## Build a tiled pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aca34c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got DMRG energy -6.46410e+00\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[211]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000012)]\n",
      "Operator(s) added to ansatz: [211]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [211]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -3.828427124746197\n",
      "(change of -0.8284271247461925)\n",
      "Current ansatz: [211]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.78207252017211\n",
      "Operators under consideration (1):\n",
      "[244]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-3.4142135623691776)]\n",
      "Operator(s) added to ansatz: [244]\n",
      "Initial energy: -3.828427124746197\n",
      "Optimizing energy with indices [211, 244]...\n",
      "Starting point: [np.float64(-0.3926990817001106), np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.626284539634967\n",
      "(change of -0.79785741488877)\n",
      "Current ansatz: [211, 244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 12.26780273103219\n",
      "Operators under consideration (1):\n",
      "[74]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(3.7252880124103616)]\n",
      "Operator(s) added to ansatz: [74]\n",
      "Initial energy: -4.626284539634967\n",
      "Optimizing energy with indices [211, 244, 74]...\n",
      "Starting point: [np.float64(-0.2651612351142246), np.float64(0.44546905146305454), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625614723\n",
      "(change of -1.4968210859797564)\n",
      "Current ansatz: [211, 244, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917530720139634\n",
      "Operators under consideration (1):\n",
      "[201]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.4850735669955735)]\n",
      "Operator(s) added to ansatz: [201]\n",
      "Initial energy: -6.123105625614723\n",
      "Optimizing energy with indices [211, 244, 74, 201]...\n",
      "Starting point: [np.float64(-0.12248992862088759), np.float64(0.785398163378279), np.float64(-0.785398163289765), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819709\n",
      "(change of -0.20417052920498602)\n",
      "Current ansatz: [211, 244, 74, 201]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580956022\n",
      "Operators under consideration (1):\n",
      "[225]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.089492926730316)]\n",
      "Operator(s) added to ansatz: [225]\n",
      "Initial energy: -6.327276154819709\n",
      "Optimizing energy with indices [211, 244, 74, 201, 225]...\n",
      "Starting point: [np.float64(-0.16357019750385363), np.float64(0.7853981628342169), np.float64(-0.7853981633513081), np.float64(0.1635696367106095), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615135384\n",
      "(change of -0.13682546031567444)\n",
      "Current ansatz: [211, 244, 74, 201, 225]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 2.5891122036896105e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580956022 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[241]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000005)]\n",
      "Operator(s) added to ansatz: [241]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operators under consideration (1):\n",
      "[79]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [79]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 79]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002093)\n",
      "Current ansatz: [241, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132733\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.0)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [241, 79, 228]...\n",
      "Starting point: [np.float64(-0.785398171825775), np.float64(0.7853981815917083), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617642\n",
      "(change of -0.1231056256176366)\n",
      "Current ansatz: [241, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917526199441697\n",
      "Operators under consideration (1):\n",
      "[198]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.4850710474288453)]\n",
      "Operator(s) added to ansatz: [198]\n",
      "Initial energy: -6.123105625617642\n",
      "Optimizing energy with indices [241, 79, 228, 198]...\n",
      "Starting point: [np.float64(-0.785398162647287), np.float64(0.7853981641254796), np.float64(0.1224892793433147), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154819708\n",
      "(change of -0.2041705292020657)\n",
      "Current ansatz: [241, 79, 228, 198]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531757\n",
      "Operators under consideration (1):\n",
      "[210]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.089492926734934)]\n",
      "Operator(s) added to ansatz: [210]\n",
      "Initial energy: -6.327276154819708\n",
      "Optimizing energy with indices [241, 79, 228, 198, 210]...\n",
      "Starting point: [np.float64(-0.7853981618473267), np.float64(0.7853981651745618), np.float64(0.16357019740836948), np.float64(-0.16356963668286137), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615134318\n",
      "(change of -0.1368254603146104)\n",
      "Current ansatz: [241, 79, 228, 198, 210]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 2.9260899740755612e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531757 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[199]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000012)]\n",
      "Operator(s) added to ansatz: [199]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [199]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -3.828427124746197\n",
      "(change of -0.8284271247461925)\n",
      "Current ansatz: [199]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.78207252017211\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(3.4142135623691776)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -3.828427124746197\n",
      "Optimizing energy with indices [199, 228]...\n",
      "Starting point: [np.float64(0.39269908170011053), np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.626284539634973\n",
      "(change of -0.7978574148887763)\n",
      "Current ansatz: [199, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 12.26780273103221\n",
      "Operators under consideration (1):\n",
      "[74]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(3.7252880124103664)]\n",
      "Operator(s) added to ansatz: [74]\n",
      "Initial energy: -4.626284539634973\n",
      "Optimizing energy with indices [199, 228, 74]...\n",
      "Starting point: [np.float64(0.2651612351142249), np.float64(-0.4454690514630537), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -5.99999999947531\n",
      "(change of -1.3737154598403372)\n",
      "Current ansatz: [199, 228, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958972842288\n",
      "Operators under consideration (1):\n",
      "[210]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.0000000010469514)]\n",
      "Operator(s) added to ansatz: [210]\n",
      "Initial energy: -5.99999999947531\n",
      "Optimizing energy with indices [199, 228, 74, 210]...\n",
      "Starting point: [np.float64(3.9073961917877325e-07), np.float64(-0.785409698652679), np.float64(-0.7854095118369314), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625542284\n",
      "(change of -0.12310562606697406)\n",
      "Current ansatz: [199, 228, 74, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.91752481649\n",
      "Operators under consideration (1):\n",
      "[225]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.4850702765206796)]\n",
      "Operator(s) added to ansatz: [225]\n",
      "Initial energy: -6.123105625542284\n",
      "Optimizing energy with indices [199, 228, 74, 210, 225]...\n",
      "Starting point: [np.float64(-2.830900313441642e-06), np.float64(-0.7854008952237638), np.float64(-0.7854013181331752), np.float64(0.12248908073453671), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154710374\n",
      "(change of -0.2041705291680893)\n",
      "Current ansatz: [199, 228, 74, 210, 225]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 6.240960102324599\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 8.91752481649 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[211]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000012)]\n",
      "Operator(s) added to ansatz: [211]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [211]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -3.828427124746197\n",
      "(change of -0.8284271247461925)\n",
      "Current ansatz: [211]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.78207252017211\n",
      "Operators under consideration (1):\n",
      "[225]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-3.4142135623691776)]\n",
      "Operator(s) added to ansatz: [225]\n",
      "Initial energy: -3.828427124746197\n",
      "Optimizing energy with indices [211, 225]...\n",
      "Starting point: [np.float64(-0.3926990817001106), np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.6262845396349705\n",
      "(change of -0.7978574148887736)\n",
      "Current ansatz: [211, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 12.267802731032203\n",
      "Operators under consideration (1):\n",
      "[79]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-3.725288012410365)]\n",
      "Operator(s) added to ansatz: [79]\n",
      "Initial energy: -4.6262845396349705\n",
      "Optimizing energy with indices [211, 225, 79]...\n",
      "Starting point: [np.float64(-0.26516123511422496), np.float64(0.4454690514630536), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -5.999999999475319\n",
      "(change of -1.3737154598403487)\n",
      "Current ansatz: [211, 225, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958972842302\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-1.9999999973729334)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -5.999999999475319\n",
      "Optimizing energy with indices [211, 225, 79, 228]...\n",
      "Starting point: [np.float64(-3.9073961363620977e-07), np.float64(0.7854096986526952), np.float64(0.7854095118369462), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.123105625446782\n",
      "(change of -0.1231056259714629)\n",
      "Current ansatz: [211, 225, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917548366257474\n",
      "Operators under consideration (1):\n",
      "[135]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.4850834011249905)]\n",
      "Operator(s) added to ansatz: [135]\n",
      "Initial energy: -6.123105625446782\n",
      "Optimizing energy with indices [211, 225, 79, 228, 135]...\n",
      "Starting point: [np.float64(-2.6259805267926943e-06), np.float64(0.7854001390902021), np.float64(0.785395798307944), np.float64(0.12249246283513109), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154802396\n",
      "(change of -0.20417052935561397)\n",
      "Current ansatz: [211, 225, 79, 228, 135]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 6.2409631751033094\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 8.917548366257474 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[244]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [244]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operators under consideration (1):\n",
      "[79]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000007)]\n",
      "Operator(s) added to ansatz: [79]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132738\n",
      "Operators under consideration (1):\n",
      "[225]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.0000000000000018)]\n",
      "Operator(s) added to ansatz: [225]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 225]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.123105625617651\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [244, 79, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199444833\n",
      "Operators under consideration (1):\n",
      "[210]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.485071047430588)]\n",
      "Operator(s) added to ansatz: [210]\n",
      "Initial energy: -6.123105625617651\n",
      "Optimizing energy with indices [244, 79, 225, 210]...\n",
      "Starting point: [np.float64(0.7853981583089785), np.float64(0.785398168718093), np.float64(-0.12248927934376257), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819709\n",
      "(change of -0.20417052920205858)\n",
      "Current ansatz: [244, 79, 225, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580530028\n",
      "Operators under consideration (1):\n",
      "[147]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.089492926737891)]\n",
      "Operator(s) added to ansatz: [147]\n",
      "Initial energy: -6.327276154819709\n",
      "Optimizing energy with indices [244, 79, 225, 210, 147]...\n",
      "Starting point: [np.float64(0.7853981700346647), np.float64(0.7853981900506334), np.float64(-0.1635701974085294), np.float64(0.16356963668219085), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101614835283\n",
      "(change of -0.13682546001557316)\n",
      "Current ansatz: [244, 79, 225, 210, 147]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00027271978716130764\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580530028 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[244]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [244]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operators under consideration (1):\n",
      "[74]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000007)]\n",
      "Operator(s) added to ansatz: [74]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 74]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002066)\n",
      "Current ansatz: [244, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.79795897113273\n",
      "Operators under consideration (1):\n",
      "[225]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.0000000000000004)]\n",
      "Operator(s) added to ansatz: [225]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [244, 74, 225]...\n",
      "Starting point: [np.float64(0.7853981703433218), np.float64(-0.7853981783720295), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [244, 74, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526200048677\n",
      "Operators under consideration (1):\n",
      "[210]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.4850710477671423)]\n",
      "Operator(s) added to ansatz: [210]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [244, 74, 225, 210]...\n",
      "Starting point: [np.float64(0.7853981633976963), np.float64(-0.7853981633977503), np.float64(-0.12248927943049101), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.3272761548197005\n",
      "(change of -0.20417052920205325)\n",
      "Current ansatz: [244, 74, 225, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.24096258053184\n",
      "Operators under consideration (1):\n",
      "[108]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.089492926734877)]\n",
      "Operator(s) added to ansatz: [108]\n",
      "Initial energy: -6.3272761548197005\n",
      "Optimizing energy with indices [244, 74, 225, 210, 108]...\n",
      "Starting point: [np.float64(0.7853981634001291), np.float64(-0.785398163399394), np.float64(-0.16357019740837944), np.float64(0.16356963668287733), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615135412\n",
      "(change of -0.13682546031571174)\n",
      "Current ansatz: [244, 74, 225, 210, 108]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 2.5887658848507677e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.24096258053184 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000005)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [228]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499795\n",
      "(change of -1.2360679774997907)\n",
      "Current ansatz: [228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696158\n",
      "Operators under consideration (1):\n",
      "[79]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000003)]\n",
      "Operator(s) added to ansatz: [79]\n",
      "Initial energy: -4.236067977499795\n",
      "Optimizing energy with indices [228, 79]...\n",
      "Starting point: [np.float64(-0.5535743588970451), np.float64(0.0)]\n",
      "\n",
      "Current energy: -5.999999999929518\n",
      "(change of -1.7639320224297226)\n",
      "Current ansatz: [228, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971647986\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.000000000019367)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -5.999999999929518\n",
      "Optimizing energy with indices [228, 79, 228]...\n",
      "Starting point: [np.float64(-0.7853947065773552), np.float64(0.7853993777262496), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625562482\n",
      "(change of -0.1231056256329639)\n",
      "Current ansatz: [228, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917526201775814\n",
      "Operators under consideration (1):\n",
      "[210]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.4850710484682814)]\n",
      "Operator(s) added to ansatz: [210]\n",
      "Initial energy: -6.123105625562482\n",
      "Optimizing energy with indices [228, 79, 228, 210]...\n",
      "Starting point: [np.float64(-0.7853947065772693), np.float64(0.7853985308794288), np.float64(0.1224892796166995), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154765011\n",
      "(change of -0.20417052920252932)\n",
      "Current ansatz: [228, 79, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964042069117\n",
      "Operators under consideration (1):\n",
      "[198]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.089491643863324)]\n",
      "Operator(s) added to ansatz: [198]\n",
      "Initial energy: -6.327276154765011\n",
      "Optimizing energy with indices [228, 79, 228, 210, 198]...\n",
      "Starting point: [np.float64(-0.78539470657713), np.float64(0.7853982468601272), np.float64(0.16357028648716854), np.float64(0.16356997194353076), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615018015\n",
      "(change of -0.13682546025300368)\n",
      "Current ansatz: [228, 79, 228, 210, 198]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00016418668721381277\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964042069117 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[210]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000012)]\n",
      "Operator(s) added to ansatz: [210]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [210]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -3.8284271247461956\n",
      "(change of -0.8284271247461912)\n",
      "Current ansatz: [210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.7820725201721\n",
      "Operators under consideration (1):\n",
      "[244]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-3.414213562369175)]\n",
      "Operator(s) added to ansatz: [244]\n",
      "Initial energy: -3.8284271247461956\n",
      "Optimizing energy with indices [210, 244]...\n",
      "Starting point: [np.float64(0.39269908170011103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.626284539634966\n",
      "(change of -0.7978574148887705)\n",
      "Current ansatz: [210, 244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 12.267802731192509\n",
      "Operators under consideration (1):\n",
      "[74]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(3.7252880124495773)]\n",
      "Operator(s) added to ansatz: [74]\n",
      "Initial energy: -4.626284539634966\n",
      "Optimizing energy with indices [210, 244, 74]...\n",
      "Starting point: [np.float64(0.2651612350948417), np.float64(0.4454690516244888), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.123105625614726\n",
      "(change of -1.49682108597976)\n",
      "Current ansatz: [210, 244, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.91753072094677\n",
      "Operators under consideration (1):\n",
      "[201]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.4850735674454114)]\n",
      "Operator(s) added to ansatz: [201]\n",
      "Initial energy: -6.123105625614726\n",
      "Optimizing energy with indices [210, 244, 74, 201]...\n",
      "Starting point: [np.float64(0.12248992873680824), np.float64(0.785398145589034), np.float64(-0.7853981585308706), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819991\n",
      "(change of -0.2041705292052649)\n",
      "Current ansatz: [210, 244, 74, 201]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240963987160017\n",
      "Operators under consideration (1):\n",
      "[225]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.0894916918532602)]\n",
      "Operator(s) added to ansatz: [225]\n",
      "Initial energy: -6.327276154819991\n",
      "Optimizing energy with indices [210, 244, 74, 201, 225]...\n",
      "Starting point: [np.float64(0.1635702832490785), np.float64(0.7853981474177403), np.float64(-0.7853981791553547), np.float64(0.1635699594295505), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615072774\n",
      "(change of -0.13682546025278342)\n",
      "Current ansatz: [210, 244, 74, 201, 225]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.0001350433250275175\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240963987160017 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[244]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [244]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operators under consideration (1):\n",
      "[26]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000007)]\n",
      "Operator(s) added to ansatz: [26]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 26]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000014\n",
      "(change of -1.7639320225002155)\n",
      "Current ansatz: [244, 26]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132747\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.0000000000000018)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -6.000000000000014\n",
      "Optimizing energy with indices [244, 26, 228]...\n",
      "Starting point: [np.float64(0.7853981718257763), np.float64(0.7853981815917102), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.12310562561763305)\n",
      "Current ansatz: [244, 26, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199440323\n",
      "Operators under consideration (1):\n",
      "[210]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.485071047428078)]\n",
      "Operator(s) added to ansatz: [210]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [244, 26, 228, 210]...\n",
      "Starting point: [np.float64(0.7853981611549227), np.float64(0.7853981650265573), np.float64(0.1224892793431165), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.32727615481998\n",
      "(change of -0.20417052920233303)\n",
      "Current ansatz: [244, 26, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964040371926\n",
      "Operators under consideration (1):\n",
      "[147]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.0894916447538887)]\n",
      "Operator(s) added to ansatz: [147]\n",
      "Initial energy: -6.32727615481998\n",
      "Optimizing energy with indices [244, 26, 228, 210, 147]...\n",
      "Starting point: [np.float64(0.785398156811469), np.float64(0.785398154431449), np.float64(0.16357028642350993), np.float64(0.16356997171157828), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615058578\n",
      "(change of -0.13682546023859743)\n",
      "Current ansatz: [244, 26, 228, 210, 147]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.0001435936123970028\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964040371926 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[244]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [244]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operators under consideration (1):\n",
      "[26]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000007)]\n",
      "Operator(s) added to ansatz: [26]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 26]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000014\n",
      "(change of -1.7639320225002155)\n",
      "Current ansatz: [244, 26]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132747\n",
      "Operators under consideration (1):\n",
      "[201]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.0000000000000058)]\n",
      "Operator(s) added to ansatz: [201]\n",
      "Initial energy: -6.000000000000014\n",
      "Optimizing energy with indices [244, 26, 201]...\n",
      "Starting point: [np.float64(0.7853981718257763), np.float64(0.7853981815917102), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617633\n",
      "(change of -0.12310562561761884)\n",
      "Current ansatz: [244, 26, 201]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.91752620076776\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.4850710481679252)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -6.123105625617633\n",
      "Optimizing energy with indices [244, 26, 201, 228]...\n",
      "Starting point: [np.float64(0.7853981623804095), np.float64(0.7853981628011234), np.float64(0.12248927953377206), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154819943\n",
      "(change of -0.20417052920230994)\n",
      "Current ansatz: [244, 26, 201, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964119013302\n",
      "Operators under consideration (1):\n",
      "[216]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.0894915756965067)]\n",
      "Operator(s) added to ansatz: [216]\n",
      "Initial energy: -6.327276154819943\n",
      "Optimizing energy with indices [244, 26, 201, 228, 216]...\n",
      "Starting point: [np.float64(0.7853982147172043), np.float64(0.7853982023026392), np.float64(0.16357029121900768), np.float64(0.16356998975892215), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.46410161478899\n",
      "(change of -0.13682545996904683)\n",
      "Current ansatz: [244, 26, 201, 228, 216]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00026970019331516135\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964119013302 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[244]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [244]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operators under consideration (1):\n",
      "[74]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000007)]\n",
      "Operator(s) added to ansatz: [74]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 74]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002066)\n",
      "Current ansatz: [244, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.79795897113273\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.0000000000000004)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [244, 74, 228]...\n",
      "Starting point: [np.float64(0.7853981703433218), np.float64(-0.7853981783720295), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [244, 74, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.91752620004858\n",
      "Operators under consideration (1):\n",
      "[135]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.485071047767087)]\n",
      "Operator(s) added to ansatz: [135]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [244, 74, 228, 135]...\n",
      "Starting point: [np.float64(0.7853981659552435), np.float64(-0.7853981611613353), np.float64(0.12248927943047701), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819995\n",
      "(change of -0.20417052920234813)\n",
      "Current ansatz: [244, 74, 228, 135]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964036853147\n",
      "Operators under consideration (1):\n",
      "[198]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.0894916478441266)]\n",
      "Operator(s) added to ansatz: [198]\n",
      "Initial energy: -6.327276154819995\n",
      "Optimizing energy with indices [244, 74, 228, 135, 198]...\n",
      "Starting point: [np.float64(0.7853981618189839), np.float64(-0.7853981597964016), np.float64(0.1635702862089859), np.float64(0.16356997090400094), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.4641016150727815\n",
      "(change of -0.13682546025278608)\n",
      "Current ansatz: [244, 74, 228, 135, 198]\n",
      "Performing final convergence check...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 0.00013504800204974552\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964036853147 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[244]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [244]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operators under consideration (1):\n",
      "[74]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000007)]\n",
      "Operator(s) added to ansatz: [74]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 74]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002066)\n",
      "Current ansatz: [244, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.79795897113273\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.0000000000000004)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [244, 74, 228]...\n",
      "Starting point: [np.float64(0.7853981703433218), np.float64(-0.7853981783720295), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [244, 74, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.91752620004858\n",
      "Operators under consideration (1):\n",
      "[210]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.4850710477670868)]\n",
      "Operator(s) added to ansatz: [210]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [244, 74, 228, 210]...\n",
      "Starting point: [np.float64(0.7853981659552435), np.float64(-0.7853981611613353), np.float64(0.12248927943047701), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.3272761548199865\n",
      "(change of -0.20417052920233925)\n",
      "Current ansatz: [244, 74, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964042725676\n",
      "Operators under consideration (1):\n",
      "[198]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.0894916426871495)]\n",
      "Operator(s) added to ansatz: [198]\n",
      "Initial energy: -6.3272761548199865\n",
      "Optimizing energy with indices [244, 74, 228, 210, 198]...\n",
      "Starting point: [np.float64(0.7853981633887943), np.float64(-0.7853981634091799), np.float64(0.1635702865670706), np.float64(0.16356997225170858), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615072771\n",
      "(change of -0.1368254602527843)\n",
      "Current ansatz: [244, 74, 228, 210, 198]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00013503875486771394\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964042725676 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[244]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [244]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operators under consideration (1):\n",
      "[79]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000007)]\n",
      "Operator(s) added to ansatz: [79]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132738\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.000000000000001)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 228]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617639\n",
      "(change of -0.12310562561763039)\n",
      "Current ansatz: [244, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199442337\n",
      "Operators under consideration (1):\n",
      "[198]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.485071047429203)]\n",
      "Operator(s) added to ansatz: [198]\n",
      "Initial energy: -6.123105625617639\n",
      "Optimizing energy with indices [244, 79, 228, 198]...\n",
      "Starting point: [np.float64(0.785398163526392), np.float64(0.7853981635468582), np.float64(0.12248927934340699), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819706\n",
      "(change of -0.20417052920206658)\n",
      "Current ansatz: [244, 79, 228, 198]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531788\n",
      "Operators under consideration (1):\n",
      "[120]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.0894929267348807)]\n",
      "Operator(s) added to ansatz: [120]\n",
      "Initial energy: -6.327276154819706\n",
      "Optimizing energy with indices [244, 79, 228, 198, 120]...\n",
      "Starting point: [np.float64(0.7853981646905418), np.float64(0.7853981643651434), np.float64(0.16357019740836648), np.float64(-0.1635696366828733), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615131534\n",
      "(change of -0.13682546031182774)\n",
      "Current ansatz: [244, 79, 228, 198, 120]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 3.672109650026482e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531788 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000005)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [228]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499795\n",
      "(change of -1.2360679774997907)\n",
      "Current ansatz: [228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696158\n",
      "Operators under consideration (1):\n",
      "[74]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000003)]\n",
      "Operator(s) added to ansatz: [74]\n",
      "Initial energy: -4.236067977499795\n",
      "Optimizing energy with indices [228, 74]...\n",
      "Starting point: [np.float64(-0.5535743588970451), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -5.999999999998185\n",
      "(change of -1.7639320224983894)\n",
      "Current ansatz: [228, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971140567\n",
      "Operators under consideration (1):\n",
      "[210]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.0000000000024785)]\n",
      "Operator(s) added to ansatz: [210]\n",
      "Initial energy: -5.999999999998185\n",
      "Optimizing energy with indices [228, 74, 210]...\n",
      "Starting point: [np.float64(-0.7853985607314252), np.float64(-0.7853989420959435), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625156506\n",
      "(change of -0.12310562515832135)\n",
      "Current ansatz: [228, 74, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917524647985756\n",
      "Operators under consideration (1):\n",
      "[180]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.4850701803347293)]\n",
      "Operator(s) added to ansatz: [180]\n",
      "Initial energy: -6.123105625156506\n",
      "Optimizing energy with indices [228, 74, 210, 180]...\n",
      "Starting point: [np.float64(-0.7854083594358539), np.float64(-0.7854119606461888), np.float64(0.12248905660281113), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154570217\n",
      "(change of -0.2041705294137115)\n",
      "Current ansatz: [228, 74, 210, 180]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240942647928968\n",
      "Operators under consideration (1):\n",
      "[57]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.0895108433634917)]\n",
      "Operator(s) added to ansatz: [57]\n",
      "Initial energy: -6.327276154570217\n",
      "Optimizing energy with indices [228, 74, 210, 180, 57]...\n",
      "Starting point: [np.float64(-0.7853992293019694), np.float64(-0.785402661890199), np.float64(0.16356498385341114), np.float64(-0.16356905917020215), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.4641016145392625\n",
      "(change of -0.13682545996904505)\n",
      "Current ansatz: [228, 74, 210, 180, 57]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.0003771958284582009\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240942647928968 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[241]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000005)]\n",
      "Operator(s) added to ansatz: [241]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operators under consideration (1):\n",
      "[74]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000005)]\n",
      "Operator(s) added to ansatz: [74]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 74]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000004\n",
      "(change of -1.7639320225002084)\n",
      "Current ansatz: [241, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132728\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.0000000000000027)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -6.000000000000004\n",
      "Optimizing energy with indices [241, 74, 228]...\n",
      "Starting point: [np.float64(-0.7853981634264042), np.float64(-0.7853981633494633), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617643\n",
      "(change of -0.12310562561763838)\n",
      "Current ansatz: [241, 74, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526201327163\n",
      "Operators under consideration (1):\n",
      "[198]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.485071048479702)]\n",
      "Operator(s) added to ansatz: [198]\n",
      "Initial energy: -6.123105625617643\n",
      "Optimizing energy with indices [241, 74, 228, 198]...\n",
      "Starting point: [np.float64(-0.7853981639976342), np.float64(-0.7853981625399249), np.float64(0.12248927961411428), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.3272761548197165\n",
      "(change of -0.20417052920207368)\n",
      "Current ansatz: [241, 74, 228, 198]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531976\n",
      "Operators under consideration (1):\n",
      "[210]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.0894929267348807)]\n",
      "Operator(s) added to ansatz: [210]\n",
      "Initial energy: -6.3272761548197165\n",
      "Optimizing energy with indices [241, 74, 228, 198, 210]...\n",
      "Starting point: [np.float64(-0.7853981657328081), np.float64(-0.7853981589236129), np.float64(0.16357019740840653), np.float64(-0.16356963668288546), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615097822\n",
      "(change of -0.13682546027810538)\n",
      "Current ansatz: [241, 74, 228, 198, 210]\n",
      "Performing final convergence check...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.424922649146182e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531976 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[244]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [244]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operators under consideration (1):\n",
      "[79]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000007)]\n",
      "Operator(s) added to ansatz: [79]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132738\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.000000000000001)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 228]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617639\n",
      "(change of -0.12310562561763039)\n",
      "Current ansatz: [244, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199442337\n",
      "Operators under consideration (1):\n",
      "[210]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.485071047429203)]\n",
      "Operator(s) added to ansatz: [210]\n",
      "Initial energy: -6.123105625617639\n",
      "Optimizing energy with indices [244, 79, 228, 210]...\n",
      "Starting point: [np.float64(0.785398163526392), np.float64(0.7853981635468582), np.float64(0.12248927934340699), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154819987\n",
      "(change of -0.20417052920234813)\n",
      "Current ansatz: [244, 79, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964041846258\n",
      "Operators under consideration (1):\n",
      "[147]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.0894916434588646)]\n",
      "Operator(s) added to ansatz: [147]\n",
      "Initial energy: -6.327276154819987\n",
      "Optimizing energy with indices [244, 79, 228, 210, 147]...\n",
      "Starting point: [np.float64(0.7853981591889313), np.float64(0.7853981652005415), np.float64(0.16357028651334282), np.float64(0.1635699720499918), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615072685\n",
      "(change of -0.13682546025269726)\n",
      "Current ansatz: [244, 79, 228, 210, 147]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00013508605784767053\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964041846258 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[244]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [244]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operators under consideration (1):\n",
      "[79]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000007)]\n",
      "Operator(s) added to ansatz: [79]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132738\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.000000000000001)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 228]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617639\n",
      "(change of -0.12310562561763039)\n",
      "Current ansatz: [244, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917526199442337\n",
      "Operators under consideration (1):\n",
      "[210]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.485071047429203)]\n",
      "Operator(s) added to ansatz: [210]\n",
      "Initial energy: -6.123105625617639\n",
      "Optimizing energy with indices [244, 79, 228, 210]...\n",
      "Starting point: [np.float64(0.785398163526392), np.float64(0.7853981635468582), np.float64(0.12248927934340699), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.327276154819987\n",
      "(change of -0.20417052920234813)\n",
      "Current ansatz: [244, 79, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964041846258\n",
      "Operators under consideration (1):\n",
      "[198]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.0894916434588646)]\n",
      "Operator(s) added to ansatz: [198]\n",
      "Initial energy: -6.327276154819987\n",
      "Optimizing energy with indices [244, 79, 228, 210, 198]...\n",
      "Starting point: [np.float64(0.7853981591889313), np.float64(0.7853981652005415), np.float64(0.16357028651334282), np.float64(0.1635699720499918), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615072706\n",
      "(change of -0.13682546025271858)\n",
      "Current ansatz: [244, 79, 228, 210, 198]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00013508605500525537\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964041846258 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[244]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [244]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operators under consideration (1):\n",
      "[74]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000007)]\n",
      "Operator(s) added to ansatz: [74]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 74]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002066)\n",
      "Current ansatz: [244, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.79795897113273\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.0000000000000004)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [244, 74, 228]...\n",
      "Starting point: [np.float64(0.7853981703433218), np.float64(-0.7853981783720295), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [244, 74, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.91752620004858\n",
      "Operators under consideration (1):\n",
      "[198]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.4850710477670868)]\n",
      "Operator(s) added to ansatz: [198]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [244, 74, 228, 198]...\n",
      "Starting point: [np.float64(0.7853981659552435), np.float64(-0.7853981611613353), np.float64(0.12248927943047701), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819701\n",
      "(change of -0.20417052920205414)\n",
      "Current ansatz: [244, 74, 228, 198]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531868\n",
      "Operators under consideration (1):\n",
      "[210]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.0894929267348714)]\n",
      "Operator(s) added to ansatz: [210]\n",
      "Initial energy: -6.327276154819701\n",
      "Optimizing energy with indices [244, 74, 228, 198, 210]...\n",
      "Starting point: [np.float64(0.7853981767050704), np.float64(-0.7853981525341414), np.float64(0.16357019740837964), np.float64(-0.16356963668287866), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101614750662\n",
      "(change of -0.13682545993096085)\n",
      "Current ansatz: [244, 74, 228, 198, 210]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.0003109685923337023\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531868 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[244]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [244]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operators under consideration (1):\n",
      "[74]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000007)]\n",
      "Operator(s) added to ansatz: [74]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 74]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002066)\n",
      "Current ansatz: [244, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.79795897113273\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.0000000000000004)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [244, 74, 228]...\n",
      "Starting point: [np.float64(0.7853981703433218), np.float64(-0.7853981783720295), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [244, 74, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.91752620004858\n",
      "Operators under consideration (1):\n",
      "[147]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.4850710477670868)]\n",
      "Operator(s) added to ansatz: [147]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [244, 74, 228, 147]...\n",
      "Starting point: [np.float64(0.7853981659552435), np.float64(-0.7853981611613353), np.float64(0.12248927943047701), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819713\n",
      "(change of -0.2041705292020657)\n",
      "Current ansatz: [244, 74, 228, 147]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531879\n",
      "Operators under consideration (1):\n",
      "[210]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.089492926734878)]\n",
      "Operator(s) added to ansatz: [210]\n",
      "Initial energy: -6.327276154819713\n",
      "Optimizing energy with indices [244, 74, 228, 147, 210]...\n",
      "Starting point: [np.float64(0.7853981767049507), np.float64(-0.7853981525341226), np.float64(0.16357019740838014), np.float64(-0.1635696366828784), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101614750672\n",
      "(change of -0.13682545993095907)\n",
      "Current ansatz: [244, 74, 228, 147, 210]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00031096863104971493\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531879 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[244]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [244]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operators under consideration (1):\n",
      "[79]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000007)]\n",
      "Operator(s) added to ansatz: [79]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132738\n",
      "Operators under consideration (1):\n",
      "[216]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.000000000000005)]\n",
      "Operator(s) added to ansatz: [216]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 216]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.1231056256176455\n",
      "(change of -0.1231056256176366)\n",
      "Current ansatz: [244, 79, 216]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526200768382\n",
      "Operators under consideration (1):\n",
      "[225]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.485071048168266)]\n",
      "Operator(s) added to ansatz: [225]\n",
      "Initial energy: -6.1231056256176455\n",
      "Optimizing energy with indices [244, 79, 216, 225]...\n",
      "Starting point: [np.float64(0.7853981633974504), np.float64(0.7853981633974519), np.float64(-0.1224892795338588), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819982\n",
      "(change of -0.20417052920233658)\n",
      "Current ansatz: [244, 79, 216, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964041381378\n",
      "Operators under consideration (1):\n",
      "[99]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.089491643867195)]\n",
      "Operator(s) added to ansatz: [99]\n",
      "Initial energy: -6.327276154819982\n",
      "Optimizing energy with indices [244, 79, 216, 225, 99]...\n",
      "Starting point: [np.float64(0.7853981633972181), np.float64(0.7853981633972502), np.float64(-0.16357028648501623), np.float64(-0.16356997194328662), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615072794\n",
      "(change of -0.13682546025281184)\n",
      "Current ansatz: [244, 79, 216, 225, 99]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00013503877239380566\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964041381378 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[241]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000005)]\n",
      "Operator(s) added to ansatz: [241]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operators under consideration (1):\n",
      "[31]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000005)]\n",
      "Operator(s) added to ansatz: [31]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 31]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000011\n",
      "(change of -1.7639320225002146)\n",
      "Current ansatz: [241, 31]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132743\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.0000000000000018)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -6.000000000000011\n",
      "Optimizing energy with indices [241, 31, 228]...\n",
      "Starting point: [np.float64(-0.7853981718257756), np.float64(-0.7853981815917112), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.1231056256176366)\n",
      "Current ansatz: [241, 31, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199441852\n",
      "Operators under consideration (1):\n",
      "[147]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.485071047428929)]\n",
      "Operator(s) added to ansatz: [147]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [241, 31, 228, 147]...\n",
      "Starting point: [np.float64(-0.7853981609748782), np.float64(-0.785398165605737), np.float64(0.12248927934333585), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819714\n",
      "(change of -0.20417052920206658)\n",
      "Current ansatz: [241, 31, 228, 147]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531371\n",
      "Operators under consideration (1):\n",
      "[45]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.089492926735604)]\n",
      "Operator(s) added to ansatz: [45]\n",
      "Initial energy: -6.327276154819714\n",
      "Optimizing energy with indices [241, 31, 228, 147, 45]...\n",
      "Starting point: [np.float64(-0.7853981663792285), np.float64(-0.7853981742082982), np.float64(0.16357019740840556), np.float64(-0.1635696366827097), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101614969718\n",
      "(change of -0.1368254601500043)\n",
      "Current ansatz: [241, 31, 228, 147, 45]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00016850486008248775\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531371 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[244]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [244]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operators under consideration (1):\n",
      "[79]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000007)]\n",
      "Operator(s) added to ansatz: [79]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000009\n",
      "(change of -1.7639320225002102)\n",
      "Current ansatz: [244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132738\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.000000000000001)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -6.000000000000009\n",
      "Optimizing energy with indices [244, 79, 228]...\n",
      "Starting point: [np.float64(0.7853981718257751), np.float64(0.7853981815917103), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617639\n",
      "(change of -0.12310562561763039)\n",
      "Current ansatz: [244, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917526199442337\n",
      "Operators under consideration (1):\n",
      "[147]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.4850710474292024)]\n",
      "Operator(s) added to ansatz: [147]\n",
      "Initial energy: -6.123105625617639\n",
      "Optimizing energy with indices [244, 79, 228, 147]...\n",
      "Starting point: [np.float64(0.785398163526392), np.float64(0.7853981635468582), np.float64(0.12248927934340699), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819699\n",
      "(change of -0.20417052920205947)\n",
      "Current ansatz: [244, 79, 228, 147]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531783\n",
      "Operators under consideration (1):\n",
      "[135]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.089492926734874)]\n",
      "Operator(s) added to ansatz: [135]\n",
      "Initial energy: -6.327276154819699\n",
      "Optimizing energy with indices [244, 79, 228, 147, 135]...\n",
      "Starting point: [np.float64(0.7853981646904773), np.float64(0.7853981643651435), np.float64(0.16357019740836662), np.float64(-0.1635696366828739), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.4641016151326465\n",
      "(change of -0.13682546031294773)\n",
      "Current ansatz: [244, 79, 228, 147, 135]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 3.3720329358920564e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531783 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000005)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [228]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499795\n",
      "(change of -1.2360679774997907)\n",
      "Current ansatz: [228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696158\n",
      "Operators under consideration (1):\n",
      "[74]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000003)]\n",
      "Operator(s) added to ansatz: [74]\n",
      "Initial energy: -4.236067977499795\n",
      "Optimizing energy with indices [228, 74]...\n",
      "Starting point: [np.float64(-0.5535743588970451), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -5.999999999998185\n",
      "(change of -1.7639320224983894)\n",
      "Current ansatz: [228, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971140567\n",
      "Operators under consideration (1):\n",
      "[225]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(1.99999999999442)]\n",
      "Operator(s) added to ansatz: [225]\n",
      "Initial energy: -5.999999999998185\n",
      "Optimizing energy with indices [228, 74, 225]...\n",
      "Starting point: [np.float64(-0.7853985607314252), np.float64(-0.7853989420959435), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625610642\n",
      "(change of -0.12310562561245764)\n",
      "Current ansatz: [228, 74, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917522148955728\n",
      "Operators under consideration (1):\n",
      "[45]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.4850687898620123)]\n",
      "Operator(s) added to ansatz: [45]\n",
      "Initial energy: -6.123105625610642\n",
      "Optimizing energy with indices [228, 74, 225, 45]...\n",
      "Starting point: [np.float64(-0.7853983869831797), np.float64(-0.7853991695302367), np.float64(-0.12248869758310571), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.3272761548148635\n",
      "(change of -0.2041705292042213)\n",
      "Current ansatz: [228, 74, 225, 45]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962434866086\n",
      "Operators under consideration (1):\n",
      "[147]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.089493170109074)]\n",
      "Operator(s) added to ansatz: [147]\n",
      "Initial energy: -6.3272761548148635\n",
      "Optimizing energy with indices [228, 74, 225, 45, 147]...\n",
      "Starting point: [np.float64(-0.7853982948161984), np.float64(-0.7853991637531028), np.float64(-0.1635702103545667), np.float64(0.16356958140448882), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.4641016144641945\n",
      "(change of -0.13682545964933102)\n",
      "Current ansatz: [228, 74, 225, 45, 147]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.0003452448185512616\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962434866086 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[244]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [244]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operators under consideration (1):\n",
      "[31]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000007)]\n",
      "Operator(s) added to ansatz: [31]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 31]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000006\n",
      "(change of -1.7639320225002075)\n",
      "Current ansatz: [244, 31]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.79795897113273\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.0000000000000027)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -6.000000000000006\n",
      "Optimizing energy with indices [244, 31, 228]...\n",
      "Starting point: [np.float64(0.7853981634264086), np.float64(-0.7853981633494667), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617643\n",
      "(change of -0.1231056256176366)\n",
      "Current ansatz: [244, 31, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526201327163\n",
      "Operators under consideration (1):\n",
      "[108]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.4850710484797025)]\n",
      "Operator(s) added to ansatz: [108]\n",
      "Initial energy: -6.123105625617643\n",
      "Optimizing energy with indices [244, 31, 228, 108]...\n",
      "Starting point: [np.float64(0.7853981639978813), np.float64(-0.7853981625399111), np.float64(0.12248927961411445), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819687\n",
      "(change of -0.20417052920204437)\n",
      "Current ansatz: [244, 31, 228, 108]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531948\n",
      "Operators under consideration (1):\n",
      "[135]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.08949292673487)]\n",
      "Operator(s) added to ansatz: [135]\n",
      "Initial energy: -6.327276154819687\n",
      "Optimizing energy with indices [244, 31, 228, 108, 135]...\n",
      "Starting point: [np.float64(0.7853981644338249), np.float64(-0.7853981569308663), np.float64(0.16357019740840614), np.float64(-0.16356963668288535), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615004063\n",
      "(change of -0.1368254601843759)\n",
      "Current ansatz: [244, 31, 228, 108, 135]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.0001576321914593721\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531948 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[241]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000005)]\n",
      "Operator(s) added to ansatz: [241]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [241]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499796\n",
      "(change of -1.2360679774997916)\n",
      "Current ansatz: [241]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.85333868569617\n",
      "Operators under consideration (1):\n",
      "[79]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [79]\n",
      "Initial energy: -4.236067977499796\n",
      "Optimizing energy with indices [241, 79]...\n",
      "Starting point: [np.float64(-0.5535743588970441), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002093)\n",
      "Current ansatz: [241, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132733\n",
      "Operators under consideration (1):\n",
      "[225]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(1.9999999999999996)]\n",
      "Operator(s) added to ansatz: [225]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [241, 79, 225]...\n",
      "Starting point: [np.float64(-0.785398171825775), np.float64(0.7853981815917083), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [241, 79, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.91752619944251\n",
      "Operators under consideration (1):\n",
      "[210]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.485071047429297)]\n",
      "Operator(s) added to ansatz: [210]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [241, 79, 225, 210]...\n",
      "Starting point: [np.float64(-0.7853981627578538), np.float64(0.78539816425353), np.float64(-0.12248927934343061), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819705\n",
      "(change of -0.2041705292020577)\n",
      "Current ansatz: [241, 79, 225, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531791\n",
      "Operators under consideration (1):\n",
      "[57]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.089492926734878)]\n",
      "Operator(s) added to ansatz: [57]\n",
      "Initial energy: -6.327276154819705\n",
      "Optimizing energy with indices [241, 79, 225, 210, 57]...\n",
      "Starting point: [np.float64(-0.7853981607743267), np.float64(0.7853981678304174), np.float64(-0.163570197408367), np.float64(0.16356963668287403), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615009303\n",
      "(change of -0.1368254601895984)\n",
      "Current ansatz: [241, 79, 225, 210, 57]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00015614019163318827\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531791 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000005)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [228]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499795\n",
      "(change of -1.2360679774997907)\n",
      "Current ansatz: [228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696158\n",
      "Operators under consideration (1):\n",
      "[26]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000003)]\n",
      "Operator(s) added to ansatz: [26]\n",
      "Initial energy: -4.236067977499795\n",
      "Optimizing energy with indices [228, 26]...\n",
      "Starting point: [np.float64(-0.5535743588970451), np.float64(0.0)]\n",
      "\n",
      "Current energy: -5.999999999929516\n",
      "(change of -1.7639320224297208)\n",
      "Current ansatz: [228, 26]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971647986\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.0000000000193667)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -5.999999999929516\n",
      "Optimizing energy with indices [228, 26, 228]...\n",
      "Starting point: [np.float64(-0.7853947065773501), np.float64(0.785399377726245), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.1231056255624825\n",
      "(change of -0.12310562563296656)\n",
      "Current ansatz: [228, 26, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917526201775818\n",
      "Operators under consideration (1):\n",
      "[135]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.4850710484682823)]\n",
      "Operator(s) added to ansatz: [135]\n",
      "Initial energy: -6.1231056255624825\n",
      "Optimizing energy with indices [228, 26, 228, 135]...\n",
      "Starting point: [np.float64(-0.7853947065772612), np.float64(0.7853985308794263), np.float64(0.12248927961669973), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154765009\n",
      "(change of -0.20417052920252665)\n",
      "Current ansatz: [228, 26, 228, 135]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964042069115\n",
      "Operators under consideration (1):\n",
      "[147]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.089491643863325)]\n",
      "Operator(s) added to ansatz: [147]\n",
      "Initial energy: -6.327276154765009\n",
      "Optimizing energy with indices [228, 26, 228, 135, 147]...\n",
      "Starting point: [np.float64(-0.7853947065771235), np.float64(0.7853982468601091), np.float64(0.16357028648716918), np.float64(0.1635699719435305), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615018019\n",
      "(change of -0.1368254602530099)\n",
      "Current ansatz: [228, 26, 228, 135, 147]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00016418668727000914\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964042069115 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[244]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [244]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operators under consideration (1):\n",
      "[74]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000007)]\n",
      "Operator(s) added to ansatz: [74]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 74]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000005\n",
      "(change of -1.7639320225002066)\n",
      "Current ansatz: [244, 74]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.79795897113273\n",
      "Operators under consideration (1):\n",
      "[225]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.0000000000000004)]\n",
      "Operator(s) added to ansatz: [225]\n",
      "Initial energy: -6.000000000000005\n",
      "Optimizing energy with indices [244, 74, 225]...\n",
      "Starting point: [np.float64(0.7853981703433218), np.float64(-0.7853981783720295), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.12310562561764193)\n",
      "Current ansatz: [244, 74, 225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526200048677\n",
      "Operators under consideration (1):\n",
      "[45]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.485071047767142)]\n",
      "Operator(s) added to ansatz: [45]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [244, 74, 225, 45]...\n",
      "Starting point: [np.float64(0.7853981633976963), np.float64(-0.7853981633977503), np.float64(-0.12248927943049101), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154819703\n",
      "(change of -0.20417052920205592)\n",
      "Current ansatz: [244, 74, 225, 45]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240962580531842\n",
      "Operators under consideration (1):\n",
      "[198]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.089492926734878)]\n",
      "Operator(s) added to ansatz: [198]\n",
      "Initial energy: -6.327276154819703\n",
      "Optimizing energy with indices [244, 74, 225, 45, 198]...\n",
      "Starting point: [np.float64(0.7853981634015789), np.float64(-0.7853981634020162), np.float64(-0.16357019740837916), np.float64(0.16356963668287725), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101615135404\n",
      "(change of -0.1368254603157011)\n",
      "Current ansatz: [244, 74, 225, 45, 198]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 2.5887658873809706e-05\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240962580531842 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[225]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [225]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [225]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [225]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operators under consideration (1):\n",
      "[79]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000007)]\n",
      "Operator(s) added to ansatz: [79]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [225, 79]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -5.999999999998188\n",
      "(change of -1.7639320224983894)\n",
      "Current ansatz: [225, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971140572\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-1.9999999999944214)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -5.999999999998188\n",
      "Optimizing energy with indices [225, 79, 228]...\n",
      "Starting point: [np.float64(0.7853985607314237), np.float64(0.7853989420959421), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625610647\n",
      "(change of -0.12310562561245852)\n",
      "Current ansatz: [225, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917522148955765\n",
      "Operators under consideration (1):\n",
      "[210]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.4850687898689605)]\n",
      "Operator(s) added to ansatz: [210]\n",
      "Initial energy: -6.123105625610647\n",
      "Optimizing energy with indices [225, 79, 228, 210]...\n",
      "Starting point: [np.float64(0.7853983869831845), np.float64(0.7853991695302365), np.float64(0.12248869758311001), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.327276154816644\n",
      "(change of -0.20417052920599765)\n",
      "Current ansatz: [225, 79, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964056416012\n",
      "Operators under consideration (1):\n",
      "[108]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.089491640726016)]\n",
      "Operator(s) added to ansatz: [108]\n",
      "Initial energy: -6.327276154816644\n",
      "Optimizing energy with indices [225, 79, 228, 210, 108]...\n",
      "Starting point: [np.float64(0.7853984379184568), np.float64(0.7853991591701261), np.float64(0.16357028929940762), np.float64(0.16356997348722394), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.464101614714416\n",
      "(change of -0.1368254598977714)\n",
      "Current ansatz: [225, 79, 228, 210, 108]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.000289389893128559\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964056416012 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[244]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [244]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [244]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -4.236067977499799\n",
      "(change of -1.2360679774997942)\n",
      "Current ansatz: [244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.853338685696167\n",
      "Operators under consideration (1):\n",
      "[26]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000007)]\n",
      "Operator(s) added to ansatz: [26]\n",
      "Initial energy: -4.236067977499799\n",
      "Optimizing energy with indices [244, 26]...\n",
      "Starting point: [np.float64(0.5535743588970456), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.000000000000014\n",
      "(change of -1.7639320225002155)\n",
      "Current ansatz: [244, 26]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 9.797958971132747\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.0000000000000018)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -6.000000000000014\n",
      "Optimizing energy with indices [244, 26, 228]...\n",
      "Starting point: [np.float64(0.7853981718257763), np.float64(0.7853981815917102), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -6.123105625617647\n",
      "(change of -0.12310562561763305)\n",
      "Current ansatz: [244, 26, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 8.917526199440323\n",
      "Operators under consideration (1):\n",
      "[210]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.485071047428078)]\n",
      "Operator(s) added to ansatz: [210]\n",
      "Initial energy: -6.123105625617647\n",
      "Optimizing energy with indices [244, 26, 228, 210]...\n",
      "Starting point: [np.float64(0.7853981611549227), np.float64(0.7853981650265573), np.float64(0.1224892793431165), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.32727615481998\n",
      "(change of -0.20417052920233303)\n",
      "Current ansatz: [244, 26, 228, 210]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 6.240964040371926\n",
      "Operators under consideration (1):\n",
      "[57]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(2.0894916447538883)]\n",
      "Operator(s) added to ansatz: [57]\n",
      "Initial energy: -6.32727615481998\n",
      "Optimizing energy with indices [244, 26, 228, 210, 57]...\n",
      "Starting point: [np.float64(0.785398156811469), np.float64(0.785398154431449), np.float64(0.16357028642350993), np.float64(0.16356997171157828), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.46410161501509\n",
      "(change of -0.13682546019510955)\n",
      "Current ansatz: [244, 26, 228, 210, 57]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 0.00016943852352460328\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 6.240964040371926 > 1e-05)\n",
      "\n",
      "Initial energy: -3.0000000000000044\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 19.595917942265466\n",
      "Operators under consideration (1):\n",
      "[198]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(4.000000000000012)]\n",
      "Operator(s) added to ansatz: [198]\n",
      "Initial energy: -3.0000000000000044\n",
      "Optimizing energy with indices [198]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "\n",
      "Current energy: -3.8284271247461965\n",
      "(change of -0.8284271247461921)\n",
      "Current ansatz: [198]\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 14.782072520172104\n",
      "Operators under consideration (1):\n",
      "[244]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-3.414213562369176)]\n",
      "Operator(s) added to ansatz: [244]\n",
      "Initial energy: -3.8284271247461965\n",
      "Optimizing energy with indices [198, 244]...\n",
      "Starting point: [np.float64(-0.3926990817001112), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current energy: -4.626284539634971\n",
      "(change of -0.7978574148887749)\n",
      "Current ansatz: [198, 244]\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "Total gradient norm: 12.267802768730808\n",
      "Operators under consideration (1):\n",
      "[79]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-3.7252880369998884)]\n",
      "Operator(s) added to ansatz: [79]\n",
      "Initial energy: -4.626284539634971\n",
      "Optimizing energy with indices [198, 244, 79]...\n",
      "Starting point: [np.float64(-0.2651612229607243), np.float64(0.4454690709399146), np.float64(0.0)]\n",
      "\n",
      "Current energy: -5.99999999941725\n",
      "(change of -1.3737154597822787)\n",
      "Current ansatz: [198, 244, 79]\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 9.79795897018112\n",
      "Operators under consideration (1):\n",
      "[228]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-1.9999999998057545)]\n",
      "Operator(s) added to ansatz: [228]\n",
      "Initial energy: -5.99999999941725\n",
      "Optimizing energy with indices [198, 244, 79, 228]...\n",
      "Starting point: [np.float64(-9.855305244099077e-06), np.float64(0.7853981714334953), np.float64(0.7853981407343851), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.123105625041502\n",
      "(change of -0.12310562562425176)\n",
      "Current ansatz: [198, 244, 79, 228]\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gradient norm: 8.917526200501854\n",
      "Operators under consideration (1):\n",
      "[210]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-2.4850710482493277)]\n",
      "Operator(s) added to ansatz: [210]\n",
      "Initial energy: -6.123105625041502\n",
      "Optimizing energy with indices [198, 244, 79, 228, 210]...\n",
      "Starting point: [np.float64(-9.693230674187634e-06), np.float64(0.7853983074098867), np.float64(0.7853977639852979), np.float64(0.12248927961503825), np.float64(0.0)]\n",
      "\n",
      "Current energy: -6.3272761542714075\n",
      "(change of -0.20417052922990564)\n",
      "Current ansatz: [198, 244, 79, 228, 210]\n",
      "Performing final convergence check...\n",
      "Total gradient norm: 6.240962748728147\n",
      "\n",
      "The maximum number of iterations (5) was hit before the convergence criterion was satisfied.\n",
      "(current gradient norm is 8.917526200501854 > 1e-05)\n",
      "Pool will be tiled from 22 ops\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    }
   ],
   "source": [
    "max_mpo_bond = 100\n",
    "dmrg_mps_bond = 10\n",
    "adapt_mps_bond = 10\n",
    "l = 4\n",
    "\n",
    "j_xy = 1\n",
    "j_z = 1\n",
    "h = XXZHamiltonian(j_xy, j_z, l, diag_mode=\"quimb\", max_mpo_bond=max_mpo_bond, max_mps_bond=dmrg_mps_bond)\n",
    "dmrg_energy = h.ground_energy\n",
    "print(f\"Got DMRG energy {dmrg_energy:4.5e}\")\n",
    "pool = FullPauliPool(n=l, max_mpo_bond=max_mpo_bond)\n",
    "\n",
    "# Run 200 iterations of ADAPT-VQE for small problem instance, selecting randomly among degenerate gradients.\n",
    "# Form a list of all unique operators ever selected for this small instance.\n",
    "ixs = []\n",
    "for _ in range(30):\n",
    "    my_adapt = TensorNetAdapt(\n",
    "        pool=pool,\n",
    "        custom_hamiltonian=h,\n",
    "        verbose=False,\n",
    "        threshold=10**-5,\n",
    "        max_adapt_iter=5,\n",
    "        max_opt_iter=10000,\n",
    "        sel_criterion=\"gradient\",\n",
    "        recycle_hessian=False,\n",
    "        rand_degenerate=True,\n",
    "        max_mpo_bond=100,\n",
    "        max_mps_bond = 20\n",
    "    )\n",
    "    my_adapt.run()\n",
    "    data = my_adapt.data\n",
    "    for i in data.result.ansatz.indices:\n",
    "        if i not in ixs:\n",
    "            ixs.append(i)\n",
    "\n",
    "print(f\"Pool will be tiled from {len(ixs)} ops\")\n",
    "source_ops = [pool.operators[index].operator for index in ixs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759f9939",
   "metadata": {},
   "source": [
    "## Run ADAPT at larger size to get a sequence of circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8a9715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neel_circuit(nq, start_zero=True):\n",
    "    circuit = QuantumCircuit(nq)\n",
    "    for i in range(nq):\n",
    "        if (i % 2 == 0 and start_zero) or (i % 2 != 0 and not start_zero):\n",
    "            circuit.x(i)\n",
    "        else:\n",
    "            circuit.id(i)\n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fb433a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got DMRG energy -2.76469e+01\n",
      "Tiled pool has 202 operators.\n",
      "\n",
      "tensor-net-adapt prepared with the following settings:\n",
      "> Pool: tiled_pauli_pool\n",
      "> Custom Hamiltonian: XXZ_1_1\n",
      "> Orbital Optimization: False\n",
      "> Selection method: gradient\n",
      "> Convergence criterion: total_g_norm\n",
      "> Recycling Hessian: False\n",
      "> Tetris: False (progressive optimization: False)\n",
      "> Convergence threshold (gradient norm):  1e-05\n",
      "> Maximum number of iterations:  30\n",
      "> candidates per iteration:  1\n",
      "\n",
      "Initial energy: -14.999999999999936\n",
      "On iteration 0.\n",
      "\n",
      "*** ADAPT-VQE Iteration 1 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 4.000000000000002\n",
      "Operator 1: -3.9999999999999853\n",
      "Operator 2: 3.9999999999999782\n",
      "Operator 3: -3.9999999999999756\n",
      "Operator 4: 3.9999999999999787\n",
      "Operator 5: -3.9999999999999822\n",
      "Operator 6: 4.000000000000005\n",
      "Operator 7: -3.999999999999995\n",
      "Operator 8: 3.9999999999999885\n",
      "Operator 9: -3.999999999999975\n",
      "Operator 10: 3.999999999999987\n",
      "Operator 11: -3.999999999999984\n",
      "Operator 12: 3.999999999999991\n",
      "Operator 13: -3.9999999999999916\n",
      "Operator 14: 3.9999999999999702\n",
      "Operator 15: -4.000000000000002\n",
      "Operator 16: 3.9999999999999853\n",
      "Operator 17: -3.9999999999999782\n",
      "Operator 18: 3.9999999999999756\n",
      "Operator 19: -3.9999999999999787\n",
      "Operator 20: 3.9999999999999822\n",
      "Operator 21: -4.000000000000005\n",
      "Operator 22: 3.999999999999995\n",
      "Operator 23: -3.9999999999999885\n",
      "Operator 24: 3.999999999999975\n",
      "Operator 25: -3.999999999999987\n",
      "Operator 26: 3.999999999999984\n",
      "Operator 40: -3.9999999999999853\n",
      "Operator 41: -3.9999999999999782\n",
      "Operator 42: -3.9999999999999756\n",
      "Operator 43: -3.9999999999999787\n",
      "Operator 44: -3.9999999999999822\n",
      "Operator 45: -4.000000000000005\n",
      "Operator 46: -3.999999999999995\n",
      "Operator 47: -3.9999999999999885\n",
      "Operator 48: -3.999999999999975\n",
      "Operator 49: -3.999999999999987\n",
      "Operator 50: -3.999999999999984\n",
      "Operator 51: -3.999999999999991\n",
      "Operator 52: -3.9999999999999916\n",
      "Operator 53: 3.9999999999999853\n",
      "Operator 54: -3.9999999999999782\n",
      "Operator 55: 3.9999999999999756\n",
      "Operator 56: -3.9999999999999787\n",
      "Operator 57: 3.9999999999999822\n",
      "Operator 58: -4.000000000000005\n",
      "Operator 59: 3.999999999999995\n",
      "Operator 60: -3.9999999999999885\n",
      "Operator 61: 3.999999999999975\n",
      "Operator 62: -3.999999999999987\n",
      "Operator 63: 3.999999999999984\n",
      "Operator 64: -3.999999999999991\n",
      "Operator 65: 3.9999999999999916\n",
      "Operator 66: -3.9999999999999702\n",
      "Operator 67: 3.9999999999999853\n",
      "Operator 68: 3.9999999999999782\n",
      "Operator 69: 3.9999999999999756\n",
      "Operator 70: 3.9999999999999787\n",
      "Operator 71: 3.9999999999999822\n",
      "Operator 72: 4.000000000000005\n",
      "Operator 73: 3.999999999999995\n",
      "Operator 74: 3.9999999999999885\n",
      "Operator 75: 3.999999999999975\n",
      "Operator 76: 3.999999999999987\n",
      "Operator 77: 3.999999999999984\n",
      "Operator 78: 3.999999999999991\n",
      "Operator 79: 3.9999999999999916\n",
      "Operator 80: 4.000000000000002\n",
      "Operator 81: 3.9999999999999853\n",
      "Operator 82: 3.9999999999999782\n",
      "Operator 83: 3.9999999999999756\n",
      "Operator 84: 3.9999999999999787\n",
      "Operator 85: 3.9999999999999822\n",
      "Operator 86: 4.000000000000005\n",
      "Operator 87: 3.999999999999995\n",
      "Operator 88: 3.9999999999999885\n",
      "Operator 89: 3.999999999999975\n",
      "Operator 90: 3.999999999999987\n",
      "Operator 91: 3.999999999999984\n",
      "Operator 92: 3.999999999999991\n",
      "Operator 93: -4.000000000000002\n",
      "Operator 94: -3.9999999999999853\n",
      "Operator 95: -3.9999999999999782\n",
      "Operator 96: -3.9999999999999756\n",
      "Operator 97: -3.9999999999999787\n",
      "Operator 98: -3.9999999999999822\n",
      "Operator 99: -4.000000000000005\n",
      "Operator 100: -3.999999999999995\n",
      "Operator 101: -3.9999999999999885\n",
      "Operator 102: -3.999999999999975\n",
      "Operator 103: -3.999999999999987\n",
      "Operator 104: -3.999999999999984\n",
      "Operator 105: -3.999999999999991\n",
      "Operator 106: -4.000000000000002\n",
      "Operator 107: -4.000000000000002\n",
      "Operator 108: 4.000000000000002\n",
      "Operator 122: -3.9999999999999702\n",
      "Operator 123: 4.000000000000002\n",
      "Operator 124: -3.9999999999999853\n",
      "Operator 125: 3.9999999999999782\n",
      "Operator 126: -3.9999999999999756\n",
      "Operator 127: 3.9999999999999787\n",
      "Operator 128: -3.9999999999999822\n",
      "Operator 129: 4.000000000000005\n",
      "Operator 130: -3.999999999999995\n",
      "Operator 131: 3.9999999999999885\n",
      "Operator 132: -3.999999999999975\n",
      "Operator 133: 3.999999999999987\n",
      "Operator 134: -3.999999999999984\n",
      "Operator 161: -3.9999999999999853\n",
      "Operator 162: -3.9999999999999782\n",
      "Operator 163: -3.9999999999999756\n",
      "Operator 164: -3.9999999999999787\n",
      "Operator 165: -3.9999999999999822\n",
      "Operator 166: -4.000000000000005\n",
      "Operator 167: -3.999999999999995\n",
      "Operator 168: -3.9999999999999885\n",
      "Operator 169: -3.999999999999975\n",
      "Operator 170: -3.999999999999987\n",
      "Operator 171: -3.999999999999984\n",
      "Operator 172: -3.999999999999991\n",
      "Operator 173: -3.9999999999999916\n",
      "Operator 188: 3.9999999999999702\n",
      "Total gradient norm: 44.36214602563751\n",
      "Operators under consideration (1):\n",
      "[169]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-3.999999999999975)]\n",
      "Operator(s) added to ansatz: [169]\n",
      "Initial energy: -14.999999999999936\n",
      "Optimizing energy with indices [169]...\n",
      "Starting point: [np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -15.828427\n",
      "         Iterations: 4\n",
      "         Function evaluations: 6\n",
      "         Gradient evaluations: 6\n",
      "\n",
      "Current energy: -15.828427124746113\n",
      "(change of -0.8284271247461774)\n",
      "Current ansatz: [169]\n",
      "coefficients: [np.float64(0.3926990817001116)]\n",
      "indices: [169]\n",
      "On iteration 1.\n",
      "\n",
      "*** ADAPT-VQE Iteration 2 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 4.0\n",
      "Operator 1: -3.999999999999985\n",
      "Operator 2: 3.9999999999999756\n",
      "Operator 3: -3.999999999999972\n",
      "Operator 4: 3.999999999999975\n",
      "Operator 5: -3.99999999999998\n",
      "Operator 6: 4.0000000000000036\n",
      "Operator 7: -3.9999999999999925\n",
      "Operator 8: 3.414213562369158\n",
      "Operator 10: 3.4142135623691554\n",
      "Operator 11: -3.9999999999999813\n",
      "Operator 12: 3.9999999999999867\n",
      "Operator 13: -3.9999999999999876\n",
      "Operator 14: 3.999999999999969\n",
      "Operator 15: -4.0\n",
      "Operator 16: 3.999999999999985\n",
      "Operator 17: -3.9999999999999756\n",
      "Operator 18: 3.999999999999972\n",
      "Operator 19: -3.999999999999975\n",
      "Operator 20: 3.99999999999998\n",
      "Operator 21: -2.8284271247383383\n",
      "Operator 22: 3.9999999999999925\n",
      "Operator 23: -3.4142135623691563\n",
      "Operator 25: -3.4142135623691554\n",
      "Operator 26: 3.9999999999999813\n",
      "Operator 35: -1.4142135623770156\n",
      "Operator 36: 1.4142135623770127\n",
      "Operator 40: -3.999999999999985\n",
      "Operator 41: -3.9999999999999756\n",
      "Operator 42: -3.999999999999972\n",
      "Operator 43: -3.999999999999975\n",
      "Operator 44: -3.99999999999998\n",
      "Operator 45: -4.0000000000000036\n",
      "Operator 46: -3.9999999999999925\n",
      "Operator 47: -3.4142135623691563\n",
      "Operator 49: -3.4142135623691554\n",
      "Operator 50: -2.828427124738326\n",
      "Operator 51: -3.9999999999999867\n",
      "Operator 52: -3.9999999999999876\n",
      "Operator 53: 3.999999999999985\n",
      "Operator 54: -3.9999999999999756\n",
      "Operator 55: 3.999999999999972\n",
      "Operator 56: -3.999999999999975\n",
      "Operator 57: 3.99999999999998\n",
      "Operator 58: -4.0000000000000036\n",
      "Operator 59: 3.9999999999999925\n",
      "Operator 60: -3.4142135623691563\n",
      "Operator 62: -3.414213562369156\n",
      "Operator 63: 3.9999999999999813\n",
      "Operator 64: -3.9999999999999867\n",
      "Operator 65: 3.9999999999999876\n",
      "Operator 66: -3.999999999999969\n",
      "Operator 67: 3.999999999999985\n",
      "Operator 68: 3.9999999999999756\n",
      "Operator 69: 3.999999999999972\n",
      "Operator 70: 3.999999999999975\n",
      "Operator 71: 3.99999999999998\n",
      "Operator 72: 4.0000000000000036\n",
      "Operator 73: 3.9999999999999925\n",
      "Operator 74: 3.414213562369158\n",
      "Operator 76: 3.414213562369156\n",
      "Operator 77: 2.828427124738326\n",
      "Operator 78: 3.9999999999999867\n",
      "Operator 79: 3.9999999999999876\n",
      "Operator 80: 4.0\n",
      "Operator 81: 3.999999999999985\n",
      "Operator 82: 3.9999999999999756\n",
      "Operator 83: 3.999999999999972\n",
      "Operator 84: 3.999999999999975\n",
      "Operator 85: 3.99999999999998\n",
      "Operator 86: 4.0000000000000036\n",
      "Operator 87: 2.8284271247383312\n",
      "Operator 88: 3.414213562369158\n",
      "Operator 90: 3.414213562369156\n",
      "Operator 91: 3.9999999999999813\n",
      "Operator 92: 3.9999999999999867\n",
      "Operator 93: -4.0\n",
      "Operator 94: -3.999999999999985\n",
      "Operator 95: -3.9999999999999756\n",
      "Operator 96: -3.999999999999972\n",
      "Operator 97: -3.999999999999975\n",
      "Operator 98: -3.99999999999998\n",
      "Operator 99: -4.0000000000000036\n",
      "Operator 100: -2.8284271247383312\n",
      "Operator 101: -3.4142135623691563\n",
      "Operator 103: -3.4142135623691554\n",
      "Operator 104: -3.9999999999999813\n",
      "Operator 105: -3.9999999999999867\n",
      "Operator 106: -4.0\n",
      "Operator 107: -4.0\n",
      "Operator 108: 4.0\n",
      "Operator 122: -3.999999999999969\n",
      "Operator 123: 4.0\n",
      "Operator 124: -3.999999999999985\n",
      "Operator 125: 3.9999999999999756\n",
      "Operator 126: -3.999999999999972\n",
      "Operator 127: 3.999999999999975\n",
      "Operator 128: -3.99999999999998\n",
      "Operator 129: 2.8284271247383383\n",
      "Operator 130: -3.9999999999999925\n",
      "Operator 131: 3.414213562369158\n",
      "Operator 133: 3.414213562369156\n",
      "Operator 134: -3.9999999999999813\n",
      "Operator 143: 1.414213562377014\n",
      "Operator 144: -1.414213562377015\n",
      "Operator 161: -3.999999999999985\n",
      "Operator 162: -3.9999999999999756\n",
      "Operator 163: -3.999999999999972\n",
      "Operator 164: -3.999999999999975\n",
      "Operator 165: -3.99999999999998\n",
      "Operator 166: -4.0000000000000036\n",
      "Operator 167: -3.9999999999999925\n",
      "Operator 168: -3.414213562369158\n",
      "Operator 170: -3.4142135623691554\n",
      "Operator 171: -2.828427124738326\n",
      "Operator 172: -2.828427124738331\n",
      "Operator 173: -3.9999999999999876\n",
      "Operator 188: 3.999999999999969\n",
      "Total gradient norm: 41.10746132382849\n",
      "Operators under consideration (1):\n",
      "[188]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(3.999999999999969)]\n",
      "Operator(s) added to ansatz: [188]\n",
      "Initial energy: -15.828427124746113\n",
      "Optimizing energy with indices [169, 188]...\n",
      "Starting point: [np.float64(0.3926990817001116), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -17.064495\n",
      "         Iterations: 9\n",
      "         Function evaluations: 11\n",
      "         Gradient evaluations: 11\n",
      "\n",
      "Current energy: -17.064495102245893\n",
      "(change of -1.2360679774997791)\n",
      "Current ansatz: [169, 188]\n",
      "coefficients: [np.float64(0.392699081716359), np.float64(-0.5535743588813512)]\n",
      "indices: [169, 188]\n",
      "On iteration 2.\n",
      "\n",
      "*** ADAPT-VQE Iteration 3 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 2.8944271910560744\n",
      "Operator 1: -3.999999999999994\n",
      "Operator 2: 3.9999999999999787\n",
      "Operator 3: -3.9999999999999765\n",
      "Operator 4: 3.9999999999999796\n",
      "Operator 5: -3.9999999999999813\n",
      "Operator 6: 4.000000000000005\n",
      "Operator 7: -3.9999999999999933\n",
      "Operator 8: 3.414213562323208\n",
      "Operator 10: 3.4142135623232033\n",
      "Operator 11: -3.999999999999983\n",
      "Operator 12: 3.9999999999999876\n",
      "Operator 13: -3.9999999999999893\n",
      "Operator 15: -2.8944271910560744\n",
      "Operator 16: 3.999999999999994\n",
      "Operator 17: -3.9999999999999787\n",
      "Operator 18: 3.9999999999999765\n",
      "Operator 19: -3.9999999999999796\n",
      "Operator 20: 3.9999999999999813\n",
      "Operator 21: -2.828427124646434\n",
      "Operator 22: 3.9999999999999933\n",
      "Operator 23: -3.414213562323206\n",
      "Operator 25: -3.4142135623232033\n",
      "Operator 26: 3.999999999999983\n",
      "Operator 35: -1.4142135624229695\n",
      "Operator 36: 1.4142135624229668\n",
      "Operator 40: -1.7888543821121252\n",
      "Operator 41: -3.9999999999999787\n",
      "Operator 42: -3.9999999999999765\n",
      "Operator 43: -3.9999999999999796\n",
      "Operator 44: -3.9999999999999813\n",
      "Operator 45: -4.000000000000005\n",
      "Operator 46: -3.9999999999999933\n",
      "Operator 47: -3.414213562323206\n",
      "Operator 49: -3.4142135623232033\n",
      "Operator 50: -2.8284271246464208\n",
      "Operator 51: -3.9999999999999876\n",
      "Operator 52: -3.9999999999999893\n",
      "Operator 53: 3.999999999999994\n",
      "Operator 54: -3.9999999999999787\n",
      "Operator 55: 3.9999999999999765\n",
      "Operator 56: -3.9999999999999796\n",
      "Operator 57: 3.9999999999999813\n",
      "Operator 58: -4.000000000000005\n",
      "Operator 59: 3.9999999999999933\n",
      "Operator 60: -3.414213562323206\n",
      "Operator 62: -3.414213562323204\n",
      "Operator 63: 3.999999999999983\n",
      "Operator 64: -3.9999999999999876\n",
      "Operator 65: 3.9999999999999893\n",
      "Operator 67: 1.7888543821121252\n",
      "Operator 68: 3.9999999999999787\n",
      "Operator 69: 3.9999999999999765\n",
      "Operator 70: 3.9999999999999796\n",
      "Operator 71: 3.9999999999999813\n",
      "Operator 72: 4.000000000000005\n",
      "Operator 73: 3.9999999999999933\n",
      "Operator 74: 3.414213562323208\n",
      "Operator 76: 3.414213562323204\n",
      "Operator 77: 2.8284271246464208\n",
      "Operator 78: 3.9999999999999876\n",
      "Operator 79: 3.9999999999999893\n",
      "Operator 80: 2.894427191056067\n",
      "Operator 81: 3.999999999999994\n",
      "Operator 82: 3.9999999999999787\n",
      "Operator 83: 3.9999999999999765\n",
      "Operator 84: 3.9999999999999796\n",
      "Operator 85: 3.9999999999999813\n",
      "Operator 86: 4.000000000000005\n",
      "Operator 87: 2.828427124646425\n",
      "Operator 88: 3.414213562323208\n",
      "Operator 90: 3.414213562323204\n",
      "Operator 91: 3.999999999999983\n",
      "Operator 92: 3.9999999999999876\n",
      "Operator 93: -2.8944271910560744\n",
      "Operator 94: -3.999999999999994\n",
      "Operator 95: -3.9999999999999787\n",
      "Operator 96: -3.9999999999999765\n",
      "Operator 97: -3.9999999999999796\n",
      "Operator 98: -3.9999999999999813\n",
      "Operator 99: -4.000000000000005\n",
      "Operator 100: -2.828427124646425\n",
      "Operator 101: -3.414213562323206\n",
      "Operator 103: -3.4142135623232033\n",
      "Operator 104: -3.999999999999983\n",
      "Operator 105: -3.9999999999999876\n",
      "Operator 106: -2.894427191056067\n",
      "Operator 107: -2.8944271910560744\n",
      "Operator 108: 2.894427191056067\n",
      "Operator 123: 2.894427191056067\n",
      "Operator 124: -3.999999999999994\n",
      "Operator 125: 3.9999999999999787\n",
      "Operator 126: -3.9999999999999765\n",
      "Operator 127: 3.9999999999999796\n",
      "Operator 128: -3.9999999999999813\n",
      "Operator 129: 2.828427124646434\n",
      "Operator 130: -3.9999999999999933\n",
      "Operator 131: 3.414213562323208\n",
      "Operator 133: 3.414213562323204\n",
      "Operator 134: -3.999999999999983\n",
      "Operator 143: 1.4142135624229681\n",
      "Operator 144: -1.414213562422969\n",
      "Operator 161: -1.7888543821121252\n",
      "Operator 162: -1.788854382112126\n",
      "Operator 163: -3.9999999999999765\n",
      "Operator 164: -3.9999999999999796\n",
      "Operator 165: -3.9999999999999813\n",
      "Operator 166: -4.000000000000005\n",
      "Operator 167: -3.9999999999999933\n",
      "Operator 168: -3.414213562323208\n",
      "Operator 170: -3.4142135623232033\n",
      "Operator 171: -2.8284271246464208\n",
      "Operator 172: -2.828427124646425\n",
      "Operator 173: -3.9999999999999893\n",
      "Operator 187: -1.7888543819717535\n",
      "Total gradient norm: 38.94669493804162\n",
      "Operators under consideration (1):\n",
      "[166]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000005)]\n",
      "Operator(s) added to ansatz: [166]\n",
      "Initial energy: -17.064495102245893\n",
      "Optimizing energy with indices [169, 188, 166]...\n",
      "Starting point: [np.float64(0.392699081716359), np.float64(-0.5535743588813512), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2492: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -17.892922\n",
      "         Iterations: 5\n",
      "         Function evaluations: 91\n",
      "         Gradient evaluations: 74\n",
      "\n",
      "Current energy: -17.89292222699219\n",
      "(change of -0.8284271247462982)\n",
      "Current ansatz: [169, 188, 166]\n",
      "coefficients: [np.float64(0.39269908300107814), np.float64(-0.5535743597228896), np.float64(0.3926990817037882)]\n",
      "indices: [169, 188, 166]\n",
      "On iteration 3.\n",
      "\n",
      "*** ADAPT-VQE Iteration 4 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 2.8944271880453085\n",
      "Operator 1: -4.0000000000000195\n",
      "Operator 2: 4.000000000000002\n",
      "Operator 3: -3.999999999999999\n",
      "Operator 4: 4.000000000000003\n",
      "Operator 5: -3.414213562358778\n",
      "Operator 7: -3.414213562358788\n",
      "Operator 8: 3.4142135586894904\n",
      "Operator 9: 1.4734439446328906e-08\n",
      "Operator 10: 3.4142135586894873\n",
      "Operator 11: -4.000000000000004\n",
      "Operator 12: 4.000000000000011\n",
      "Operator 13: -4.0000000000000115\n",
      "Operator 15: -2.8944271880453085\n",
      "Operator 16: 4.0000000000000195\n",
      "Operator 17: -4.000000000000002\n",
      "Operator 18: 2.8284271247175425\n",
      "Operator 19: -4.000000000000003\n",
      "Operator 20: 3.4142135623587753\n",
      "Operator 22: 3.414213562358788\n",
      "Operator 23: -3.4142135586894904\n",
      "Operator 24: -1.4734439446328906e-08\n",
      "Operator 25: -3.4142135586894873\n",
      "Operator 26: 4.000000000000004\n",
      "Operator 32: -1.4142135623874212\n",
      "Operator 33: 1.4142135623874263\n",
      "Operator 35: -1.4142135660567123\n",
      "Operator 36: 1.414213566056709\n",
      "Operator 40: -1.7888543760905704\n",
      "Operator 41: -4.000000000000002\n",
      "Operator 42: -3.9999999999999982\n",
      "Operator 43: -4.000000000000003\n",
      "Operator 44: -3.4142135623587753\n",
      "Operator 46: -3.414213562358788\n",
      "Operator 47: -2.414213559743944\n",
      "Operator 48: 1.4734439446328906e-08\n",
      "Operator 49: -3.4142135586894873\n",
      "Operator 50: -2.8284271173789657\n",
      "Operator 51: -4.000000000000011\n",
      "Operator 52: -4.0000000000000115\n",
      "Operator 53: 4.0000000000000195\n",
      "Operator 54: -4.000000000000002\n",
      "Operator 55: 3.9999999999999982\n",
      "Operator 56: -4.000000000000003\n",
      "Operator 57: 3.4142135623587753\n",
      "Operator 59: 3.4142135623587846\n",
      "Operator 60: -3.4142135586894904\n",
      "Operator 61: -1.4734439446328906e-08\n",
      "Operator 62: -3.414213558689488\n",
      "Operator 63: 4.000000000000004\n",
      "Operator 64: -4.000000000000011\n",
      "Operator 65: 4.0000000000000115\n",
      "Operator 67: 1.7888543760905704\n",
      "Operator 68: 4.000000000000002\n",
      "Operator 69: 3.999999999999999\n",
      "Operator 70: 4.000000000000003\n",
      "Operator 71: 3.414213562358778\n",
      "Operator 73: 3.4142135623587846\n",
      "Operator 74: 2.4142135597439434\n",
      "Operator 75: -1.4734439446328906e-08\n",
      "Operator 76: 3.414213558689488\n",
      "Operator 77: 2.8284271173789657\n",
      "Operator 78: 4.000000000000011\n",
      "Operator 79: 4.0000000000000115\n",
      "Operator 80: 2.8944271880453014\n",
      "Operator 81: 4.0000000000000195\n",
      "Operator 82: 4.000000000000002\n",
      "Operator 83: 3.9999999999999982\n",
      "Operator 84: 2.828427124717546\n",
      "Operator 85: 3.414213562358778\n",
      "Operator 87: 2.4142135560746514\n",
      "Operator 88: 3.4142135586894904\n",
      "Operator 89: -1.4734439446328906e-08\n",
      "Operator 90: 3.414213558689488\n",
      "Operator 91: 4.000000000000004\n",
      "Operator 92: 4.000000000000011\n",
      "Operator 93: -2.8944271880453085\n",
      "Operator 94: -4.0000000000000195\n",
      "Operator 95: -4.000000000000002\n",
      "Operator 96: -3.999999999999999\n",
      "Operator 97: -2.828427124717546\n",
      "Operator 98: -3.4142135623587753\n",
      "Operator 100: -2.414213556074654\n",
      "Operator 101: -3.4142135586894904\n",
      "Operator 102: 1.4734439446328906e-08\n",
      "Operator 103: -3.4142135586894873\n",
      "Operator 104: -4.000000000000004\n",
      "Operator 105: -4.000000000000011\n",
      "Operator 106: -2.8944271880453014\n",
      "Operator 107: -2.8944271880453085\n",
      "Operator 108: 2.894427188045302\n",
      "Operator 123: 2.8944271880453014\n",
      "Operator 124: -4.0000000000000195\n",
      "Operator 125: 4.000000000000002\n",
      "Operator 126: -2.8284271247175425\n",
      "Operator 127: 4.000000000000003\n",
      "Operator 128: -3.414213562358778\n",
      "Operator 130: -3.4142135623587846\n",
      "Operator 131: 3.4142135586894904\n",
      "Operator 132: 1.4734439446328906e-08\n",
      "Operator 133: 3.414213558689488\n",
      "Operator 134: -4.000000000000004\n",
      "Operator 140: 1.4142135623874148\n",
      "Operator 141: -1.414213562387417\n",
      "Operator 143: 1.414213566056711\n",
      "Operator 144: -1.4142135660567117\n",
      "Operator 161: -1.7888543760905704\n",
      "Operator 162: -1.7888543760905706\n",
      "Operator 163: -3.999999999999999\n",
      "Operator 164: -4.000000000000003\n",
      "Operator 165: -3.414213562358778\n",
      "Operator 167: -3.414213562358788\n",
      "Operator 168: -2.4142135597439434\n",
      "Operator 169: 1.0418821361213304e-08\n",
      "Operator 170: -3.4142135586894873\n",
      "Operator 171: -2.8284271173789657\n",
      "Operator 172: -2.8284271173789715\n",
      "Operator 173: -4.0000000000000115\n",
      "Operator 187: -1.7888543834771555\n",
      "Total gradient norm: 35.68650006165638\n",
      "Operators under consideration (1):\n",
      "[173]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.0000000000000115)]\n",
      "Operator(s) added to ansatz: [173]\n",
      "Initial energy: -17.89292222699219\n",
      "Optimizing energy with indices [169, 188, 166, 173]...\n",
      "Starting point: [np.float64(0.39269908300107814), np.float64(-0.5535743597228896), np.float64(0.3926990817037882), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -19.128990\n",
      "         Iterations: 11\n",
      "         Function evaluations: 35\n",
      "         Gradient evaluations: 33\n",
      "\n",
      "Current energy: -19.12899020449192\n",
      "(change of -1.2360679774997294)\n",
      "Current ansatz: [169, 188, 166, 173]\n",
      "coefficients: [np.float64(0.39269908169856693), np.float64(-0.5535743588970696), np.float64(0.3926990817372775), np.float64(0.5535743588970368)]\n",
      "indices: [169, 188, 166, 173]\n",
      "On iteration 4.\n",
      "\n",
      "*** ADAPT-VQE Iteration 5 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 2.8944271909998456\n",
      "Operator 1: -4.000000000000007\n",
      "Operator 2: 3.999999999999991\n",
      "Operator 3: -3.999999999999991\n",
      "Operator 4: 3.9999999999999925\n",
      "Operator 5: -3.4142135622640453\n",
      "Operator 7: -3.414213562264055\n",
      "Operator 8: 3.4142135623735395\n",
      "Operator 10: 3.4142135623735372\n",
      "Operator 11: -3.999999999999993\n",
      "Operator 12: 2.8944271909999415\n",
      "Operator 15: -2.8944271909998456\n",
      "Operator 16: 4.000000000000007\n",
      "Operator 17: -3.999999999999991\n",
      "Operator 18: 2.82842712452809\n",
      "Operator 19: -3.9999999999999925\n",
      "Operator 20: 3.414213562264043\n",
      "Operator 22: 3.414213562264055\n",
      "Operator 23: -3.414213562373541\n",
      "Operator 25: -1.5268827230338333\n",
      "Operator 26: 3.999999999999993\n",
      "Operator 32: -1.4142135624821404\n",
      "Operator 33: 1.4142135624821457\n",
      "Operator 35: -1.4142135623726495\n",
      "Operator 36: 1.4142135623726466\n",
      "Operator 39: -1.7888543819998148\n",
      "Operator 40: -1.788854381999657\n",
      "Operator 41: -3.999999999999992\n",
      "Operator 42: -3.999999999999991\n",
      "Operator 43: -3.9999999999999925\n",
      "Operator 44: -3.414213562264043\n",
      "Operator 46: -3.414213562264055\n",
      "Operator 47: -2.414213562187257\n",
      "Operator 49: -3.4142135623735372\n",
      "Operator 50: -2.8284271247470754\n",
      "Operator 51: -2.8944271909999397\n",
      "Operator 53: 4.000000000000007\n",
      "Operator 54: -3.999999999999992\n",
      "Operator 55: 3.999999999999991\n",
      "Operator 56: -3.9999999999999925\n",
      "Operator 57: 3.414213562264043\n",
      "Operator 59: 3.4142135622640515\n",
      "Operator 60: -3.4142135623735395\n",
      "Operator 62: -3.4142135623735372\n",
      "Operator 63: 3.999999999999993\n",
      "Operator 64: -2.8944271909999397\n",
      "Operator 67: 1.788854381999657\n",
      "Operator 68: 3.999999999999991\n",
      "Operator 69: 3.999999999999991\n",
      "Operator 70: 3.9999999999999925\n",
      "Operator 71: 3.4142135622640453\n",
      "Operator 73: 3.4142135622640515\n",
      "Operator 74: 2.414213562187257\n",
      "Operator 76: 3.4142135623735372\n",
      "Operator 77: 2.8284271247470754\n",
      "Operator 78: 2.8944271909999415\n",
      "Operator 80: 2.894427190999839\n",
      "Operator 81: 4.000000000000007\n",
      "Operator 82: 3.999999999999992\n",
      "Operator 83: 3.999999999999991\n",
      "Operator 84: 2.8284271245280923\n",
      "Operator 85: 3.4142135622640453\n",
      "Operator 87: 2.414213562296747\n",
      "Operator 88: 3.414213562373539\n",
      "Operator 90: 3.4142135623735372\n",
      "Operator 91: 1.7888543819998808\n",
      "Operator 92: 2.8944271909999415\n",
      "Operator 93: -2.8944271909998456\n",
      "Operator 94: -4.000000000000007\n",
      "Operator 95: -3.999999999999991\n",
      "Operator 96: -3.999999999999991\n",
      "Operator 97: -2.8284271245280923\n",
      "Operator 98: -3.414213562264043\n",
      "Operator 100: -2.414213562296749\n",
      "Operator 101: -3.414213562373541\n",
      "Operator 103: -3.4142135623735372\n",
      "Operator 104: -1.7888543819998808\n",
      "Operator 105: -2.8944271909999397\n",
      "Operator 106: -2.894427190999839\n",
      "Operator 107: -2.8944271909998456\n",
      "Operator 108: 2.894427190999839\n",
      "Operator 123: 2.894427190999839\n",
      "Operator 124: -4.000000000000007\n",
      "Operator 125: 3.999999999999992\n",
      "Operator 126: -2.82842712452809\n",
      "Operator 127: 3.9999999999999925\n",
      "Operator 128: -3.4142135622640453\n",
      "Operator 130: -3.4142135622640515\n",
      "Operator 131: 3.414213562373539\n",
      "Operator 133: 1.526882723033834\n",
      "Operator 134: -3.999999999999993\n",
      "Operator 140: 1.4142135624821344\n",
      "Operator 141: -1.4142135624821366\n",
      "Operator 143: 1.4142135623726486\n",
      "Operator 144: -1.414213562372649\n",
      "Operator 147: 1.7888543819998122\n",
      "Operator 161: -1.788854381999657\n",
      "Operator 162: -1.7888543819996572\n",
      "Operator 163: -3.999999999999991\n",
      "Operator 164: -3.9999999999999925\n",
      "Operator 165: -3.4142135622640453\n",
      "Operator 167: -3.414213562264055\n",
      "Operator 168: -2.414213562187257\n",
      "Operator 170: -3.4142135623735372\n",
      "Operator 171: -2.8284271247470754\n",
      "Operator 172: -2.0466690944074335\n",
      "Operator 187: -1.788854381999877\n",
      "Total gradient norm: 33.258539168427184\n",
      "Operators under consideration (1):\n",
      "[164]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-3.9999999999999925)]\n",
      "Operator(s) added to ansatz: [164]\n",
      "Initial energy: -19.12899020449192\n",
      "Optimizing energy with indices [169, 188, 166, 173, 164]...\n",
      "Starting point: [np.float64(0.39269908169856693), np.float64(-0.5535743588970696), np.float64(0.3926990817372775), np.float64(0.5535743588970368), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2492: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -20.063861\n",
      "         Iterations: 10\n",
      "         Function evaluations: 137\n",
      "         Gradient evaluations: 117\n",
      "\n",
      "Current energy: -20.063860908300356\n",
      "(change of -0.9348707038084356)\n",
      "Current ansatz: [169, 188, 166, 173, 164]\n",
      "coefficients: [np.float64(0.3926990830903995), np.float64(-0.5535743583032001), np.float64(0.4431436457312779), np.float64(0.5535743586508042), np.float64(0.4431436457666283)]\n",
      "indices: [169, 188, 166, 173, 164]\n",
      "On iteration 5.\n",
      "\n",
      "*** ADAPT-VQE Iteration 6 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 2.894427193124545\n",
      "Operator 1: -4.000000000000014\n",
      "Operator 2: 3.9999999999999964\n",
      "Operator 3: -3.2645854456701144\n",
      "Operator 5: -2.5291708914497812\n",
      "Operator 7: -3.264585445779672\n",
      "Operator 8: 3.414213558436847\n",
      "Operator 9: 1.574498295081312e-08\n",
      "Operator 10: 3.4142135584368436\n",
      "Operator 11: -3.9999999999999964\n",
      "Operator 12: 2.894427191880895\n",
      "Operator 15: -2.894427193124545\n",
      "Operator 16: 2.529170891340243\n",
      "Operator 17: -3.9999999999999964\n",
      "Operator 18: 2.0641736205492687\n",
      "Operator 20: 2.7995881747696094\n",
      "Operator 22: 3.264585445779672\n",
      "Operator 23: -3.4142135584368467\n",
      "Operator 24: -1.574498295081312e-08\n",
      "Operator 25: -1.5268827227771675\n",
      "Operator 26: 3.9999999999999964\n",
      "Operator 30: -1.5494591477671529\n",
      "Operator 31: 1.5494591477671562\n",
      "Operator 32: -1.5494591476777497\n",
      "Operator 33: 1.5494591476777553\n",
      "Operator 35: -1.414213566309347\n",
      "Operator 36: 1.414213566309344\n",
      "Operator 39: -1.7888543815593412\n",
      "Operator 40: -1.7888543862490465\n",
      "Operator 41: -3.9999999999999973\n",
      "Operator 42: -3.2645854456701127\n",
      "Operator 44: -2.7995881747696094\n",
      "Operator 45: 0.9299945415453542\n",
      "Operator 46: -3.264585445779672\n",
      "Operator 47: -2.158782387391415\n",
      "Operator 48: 1.574498295081312e-08\n",
      "Operator 49: -3.4142135584368436\n",
      "Operator 50: -2.8284271168736863\n",
      "Operator 51: -2.8944271918808933\n",
      "Operator 53: 4.000000000000014\n",
      "Operator 54: -3.9999999999999973\n",
      "Operator 55: 3.2645854456701127\n",
      "Operator 57: 2.529170891449775\n",
      "Operator 59: 3.2645854457796686\n",
      "Operator 60: -3.4142135584368467\n",
      "Operator 61: -1.574498295081312e-08\n",
      "Operator 62: -3.414213558436844\n",
      "Operator 63: 3.9999999999999964\n",
      "Operator 64: -2.8944271918808933\n",
      "Operator 67: 1.7888543862490465\n",
      "Operator 68: 3.9999999999999964\n",
      "Operator 69: 3.2645854456701144\n",
      "Operator 71: 2.7995881747696094\n",
      "Operator 72: -0.9299945415453544\n",
      "Operator 73: 3.2645854457796686\n",
      "Operator 74: 2.1587823873914154\n",
      "Operator 75: -1.574498295081312e-08\n",
      "Operator 76: 3.414213558436844\n",
      "Operator 77: 2.8284271168736863\n",
      "Operator 78: 2.894427191880895\n",
      "Operator 80: 2.8944271931245376\n",
      "Operator 81: 4.000000000000014\n",
      "Operator 82: 2.5291708913402315\n",
      "Operator 83: 3.2645854456701144\n",
      "Operator 84: -0.9299945417761788\n",
      "Operator 85: 2.7995881747696094\n",
      "Operator 87: 2.3084105000485957\n",
      "Operator 88: 3.414213558436847\n",
      "Operator 89: -1.574498295081312e-08\n",
      "Operator 90: 3.414213558436844\n",
      "Operator 91: 1.7888543837617832\n",
      "Operator 92: 2.894427191880895\n",
      "Operator 93: -2.894427193124545\n",
      "Operator 94: -4.000000000000014\n",
      "Operator 95: -2.5291708913402315\n",
      "Operator 96: -3.2645854456701127\n",
      "Operator 97: 0.929994541776178\n",
      "Operator 98: -2.7995881747696094\n",
      "Operator 100: -2.3084105000485984\n",
      "Operator 101: -3.4142135584368467\n",
      "Operator 102: 1.574498295081312e-08\n",
      "Operator 103: -3.4142135584368436\n",
      "Operator 104: -1.7888543837617832\n",
      "Operator 105: -2.8944271918808933\n",
      "Operator 106: -2.8944271931245376\n",
      "Operator 107: -2.894427193124545\n",
      "Operator 108: 2.8944271931245376\n",
      "Operator 114: 1.2004118252303932\n",
      "Operator 123: 2.8944271931245376\n",
      "Operator 124: -2.529170891340243\n",
      "Operator 125: 3.9999999999999973\n",
      "Operator 126: -2.0641736205492696\n",
      "Operator 128: -2.7995881747696094\n",
      "Operator 130: -3.2645854457796686\n",
      "Operator 131: 3.414213558436847\n",
      "Operator 132: 1.574498295081312e-08\n",
      "Operator 133: 1.5268827227771677\n",
      "Operator 134: -3.9999999999999964\n",
      "Operator 138: 1.5494591477671489\n",
      "Operator 139: -1.5494591477671515\n",
      "Operator 140: 1.5494591476777453\n",
      "Operator 141: -1.5494591476777446\n",
      "Operator 143: 1.4142135663093454\n",
      "Operator 144: -1.414213566309346\n",
      "Operator 147: 1.788854381559339\n",
      "Operator 153: -1.2004118252303937\n",
      "Operator 161: -1.7888543862490465\n",
      "Operator 162: -1.7888543862490465\n",
      "Operator 163: -3.2645854456701144\n",
      "Operator 165: -2.5291708914497812\n",
      "Operator 166: 0.9299945415453543\n",
      "Operator 167: -2.0641736204397314\n",
      "Operator 168: -2.1587823873914154\n",
      "Operator 170: -3.4142135584368436\n",
      "Operator 171: -2.8284271168736863\n",
      "Operator 172: -2.046669089333123\n",
      "Operator 179: 1.2004118252303932\n",
      "Operator 187: -1.788854380937534\n",
      "Operator 194: -1.200411825230394\n",
      "Total gradient norm: 29.31800528791582\n",
      "Operators under consideration (1):\n",
      "[94]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000014)]\n",
      "Operator(s) added to ansatz: [94]\n",
      "Initial energy: -20.063860908300356\n",
      "Optimizing energy with indices [169, 188, 166, 173, 164, 94]...\n",
      "Starting point: [np.float64(0.3926990830903995), np.float64(-0.5535743583032001), np.float64(0.4431436457312779), np.float64(0.5535743586508042), np.float64(0.4431436457666283), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2492: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -21.122828\n",
      "         Iterations: 11\n",
      "         Function evaluations: 192\n",
      "         Gradient evaluations: 173\n",
      "\n",
      "Current energy: -21.122828488982723\n",
      "(change of -1.058967580682367)\n",
      "Current ansatz: [169, 188, 166, 173, 164, 94]\n",
      "coefficients: [np.float64(0.39269908138347626), np.float64(-0.6553685211154132), np.float64(0.4431436460620996), np.float64(0.5535743579285856), np.float64(0.4431436456276534), np.float64(0.5048173547524759)]\n",
      "indices: [169, 188, 166, 173, 164, 94]\n",
      "On iteration 6.\n",
      "\n",
      "*** ADAPT-VQE Iteration 7 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 1.5786157379103312\n",
      "Operator 2: 3.064340051012463\n",
      "Operator 3: -3.2645854461007944\n",
      "Operator 5: -2.5291708908552684\n",
      "Operator 7: -3.264585444754493\n",
      "Operator 8: 3.414213563264762\n",
      "Operator 10: 3.41421356326476\n",
      "Operator 11: -4.000000000000008\n",
      "Operator 12: 2.894427194464789\n",
      "Operator 14: 3.8486843167314165e-08\n",
      "Operator 15: -2.2736821054136787\n",
      "Operator 17: -3.064340051012463\n",
      "Operator 18: 2.0641736191481774\n",
      "Operator 20: 2.799588174393705\n",
      "Operator 22: 3.264585444754493\n",
      "Operator 23: -3.414213563264761\n",
      "Operator 25: -1.5268827293472493\n",
      "Operator 26: 4.000000000000008\n",
      "Operator 27: -1.693275008913443\n",
      "Operator 28: 1.69327500891343\n",
      "Operator 30: -1.5494591474156667\n",
      "Operator 31: 1.5494591474156678\n",
      "Operator 32: -1.5494591485144569\n",
      "Operator 33: 1.549459148514462\n",
      "Operator 35: -1.4142135614814428\n",
      "Operator 36: 1.4142135614814404\n",
      "Operator 39: -1.7888543802674017\n",
      "Operator 40: 1.5813158822440678\n",
      "Operator 41: -3.064340051012463\n",
      "Operator 42: -1.737314520118724\n",
      "Operator 44: -2.799588174393705\n",
      "Operator 45: 0.9299945439965724\n",
      "Operator 46: -3.264585444754493\n",
      "Operator 47: -2.158782388693966\n",
      "Operator 49: -3.41421356326476\n",
      "Operator 50: -2.828427126529509\n",
      "Operator 51: -2.8944271944647872\n",
      "Operator 54: -3.064340051012469\n",
      "Operator 55: 3.2645854461007935\n",
      "Operator 57: 2.529170890855263\n",
      "Operator 59: 3.264585444754489\n",
      "Operator 60: -3.414213563264762\n",
      "Operator 62: -3.4142135632647603\n",
      "Operator 63: 4.000000000000008\n",
      "Operator 64: -2.8944271944647872\n",
      "Operator 66: -3.8486843356014193e-08\n",
      "Operator 67: -1.5813158822440678\n",
      "Operator 68: 3.064340051012469\n",
      "Operator 69: 1.7373145201187252\n",
      "Operator 71: 2.799588174393706\n",
      "Operator 72: -0.9299945439965724\n",
      "Operator 73: 3.264585444754489\n",
      "Operator 74: 2.158782388693966\n",
      "Operator 76: 3.4142135632647608\n",
      "Operator 77: 2.828427126529509\n",
      "Operator 78: 2.894427194464789\n",
      "Operator 80: 2.2736821054136755\n",
      "Operator 82: 1.9375599152070562\n",
      "Operator 83: 3.2645854461007957\n",
      "Operator 84: -0.9299945411600231\n",
      "Operator 85: 2.799588174393706\n",
      "Operator 87: 2.3084105072042425\n",
      "Operator 88: 3.414213563264763\n",
      "Operator 90: 3.4142135632647603\n",
      "Operator 91: 1.7888543889295627\n",
      "Operator 92: 2.894427194464789\n",
      "Operator 93: -2.2736821054136787\n",
      "Operator 95: -1.9375599152070522\n",
      "Operator 96: -3.2645854461007935\n",
      "Operator 97: 0.929994541160023\n",
      "Operator 98: -2.799588174393705\n",
      "Operator 100: -2.308410507204245\n",
      "Operator 101: -3.414213563264761\n",
      "Operator 103: -3.41421356326476\n",
      "Operator 104: -1.7888543889295627\n",
      "Operator 105: -2.8944271944647872\n",
      "Operator 106: -1.5786157379103198\n",
      "Operator 107: -2.2736821054136787\n",
      "Operator 108: 2.2736821054136755\n",
      "Operator 109: 1.636338188914569\n",
      "Operator 114: 1.200411825606305\n",
      "Operator 122: -3.848684298409881e-08\n",
      "Operator 123: 2.2736821054136755\n",
      "Operator 125: 3.064340051012469\n",
      "Operator 126: -2.064173619148179\n",
      "Operator 128: -2.799588174393706\n",
      "Operator 130: -3.264585444754489\n",
      "Operator 131: 3.414213563264763\n",
      "Operator 133: 1.5268827293472484\n",
      "Operator 134: -4.000000000000008\n",
      "Operator 135: 1.69327500891344\n",
      "Operator 136: -1.6932750089134394\n",
      "Operator 138: 1.549459147415663\n",
      "Operator 139: -1.549459147415664\n",
      "Operator 140: 1.5494591485144518\n",
      "Operator 141: -1.5494591485144513\n",
      "Operator 143: 1.4142135614814417\n",
      "Operator 144: -1.4142135614814426\n",
      "Operator 147: 1.7888543802673995\n",
      "Operator 148: -1.6363381889145683\n",
      "Operator 153: -1.200411825606305\n",
      "Operator 161: 1.5813158822440678\n",
      "Operator 162: -0.7879577923115112\n",
      "Operator 163: -1.7373145201187252\n",
      "Operator 165: -2.5291708908552684\n",
      "Operator 166: 0.9299945439965724\n",
      "Operator 167: -2.0641736204944996\n",
      "Operator 168: -2.158782388693966\n",
      "Operator 170: -3.41421356326476\n",
      "Operator 171: -2.828427126529509\n",
      "Operator 172: -2.046669098147225\n",
      "Operator 174: 1.6363381889145687\n",
      "Operator 179: 1.200411825606305\n",
      "Operator 187: -1.9327494710556203\n",
      "Operator 188: 3.8486843926583435e-08\n",
      "Operator 189: -1.6363381889145683\n",
      "Operator 194: -1.2004118256063048\n",
      "Total gradient norm: 26.493538400851318\n",
      "Operators under consideration (1):\n",
      "[134]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-4.000000000000008)]\n",
      "Operator(s) added to ansatz: [134]\n",
      "Initial energy: -21.122828488982723\n",
      "Optimizing energy with indices [169, 188, 166, 173, 164, 94, 134]...\n",
      "Starting point: [np.float64(0.39269908138347626), np.float64(-0.6553685211154132), np.float64(0.4431436460620996), np.float64(0.5535743579285856), np.float64(0.4431436456276534), np.float64(0.5048173547524759), np.float64(0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2492: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: -22.375284\n",
      "         Iterations: 13\n",
      "         Function evaluations: 53\n",
      "         Gradient evaluations: 52\n",
      "\n",
      "Current energy: -22.375284053874815\n",
      "(change of -1.2524555648920916)\n",
      "Current ansatz: [169, 188, 166, 173, 164, 94, 134]\n",
      "coefficients: [np.float64(0.4901254764438521), np.float64(-0.6553685359636564), np.float64(0.44314363106479154), np.float64(0.7010350187592747), np.float64(0.443143661711486), np.float64(0.5048173805966985), np.float64(0.6115719318015798)]\n",
      "indices: [169, 188, 166, 173, 164, 94, 134]\n",
      "On iteration 7.\n",
      "\n",
      "*** ADAPT-VQE Iteration 8 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 1.5786155929917154\n",
      "Operator 1: 1.8665872652526026e-07\n",
      "Operator 2: 3.064339963489719\n",
      "Operator 3: -3.2645853962583233\n",
      "Operator 4: -1.9983633825512492e-07\n",
      "Operator 5: -2.5291708874882275\n",
      "Operator 6: 1.90204411530141e-07\n",
      "Operator 7: -3.2645854912299344\n",
      "Operator 8: 3.11362822703031\n",
      "Operator 9: 8.105815596985563e-08\n",
      "Operator 10: 1.7950115322673232\n",
      "Operator 11: 2.1226611013336338e-07\n",
      "Operator 12: 1.0172370298054383\n",
      "Operator 13: -1.569975403015178e-07\n",
      "Operator 15: -2.273682052363916\n",
      "Operator 16: -1.1802294731415816e-07\n",
      "Operator 17: -3.064339963489719\n",
      "Operator 18: 2.0641736634946555\n",
      "Operator 19: 1.9983633825512492e-07\n",
      "Operator 20: 2.799588172264752\n",
      "Operator 21: -1.0590850024247305e-07\n",
      "Operator 22: 3.2645854912299344\n",
      "Operator 23: -1.0607871463065985\n",
      "Operator 24: -8.105815596985563e-08\n",
      "Operator 25: -0.3995658211377964\n",
      "Operator 26: -2.1226611013336338e-07\n",
      "Operator 27: -1.6932750639275276\n",
      "Operator 28: 1.6932750639275143\n",
      "Operator 30: -1.549459188094431\n",
      "Operator 31: 1.5494591880944322\n",
      "Operator 32: -1.5494591105837034\n",
      "Operator 33: 1.5494591105837097\n",
      "Operator 35: -1.6612742615117457\n",
      "Operator 36: 1.6612742615117417\n",
      "Operator 37: -1.880350177851002\n",
      "Operator 38: 1.8803501778510028\n",
      "Operator 39: -1.9715989134947178\n",
      "Operator 40: 1.5813160089103981\n",
      "Operator 41: -3.064339963489719\n",
      "Operator 42: -1.7373143507313036\n",
      "Operator 43: 1.9983633825512492e-07\n",
      "Operator 44: -2.799588172264752\n",
      "Operator 45: 0.9299944477259512\n",
      "Operator 46: -3.2645854912299344\n",
      "Operator 47: -1.9687245404932168\n",
      "Operator 48: 8.105815596985563e-08\n",
      "Operator 49: -2.379403841069583\n",
      "Operator 50: 1.2973628470393874\n",
      "Operator 51: -2.1144225604613016\n",
      "Operator 52: 1.7427537925721\n",
      "Operator 53: -1.866587272048225e-07\n",
      "Operator 54: -3.064339963489725\n",
      "Operator 55: 3.2645853962583216\n",
      "Operator 56: 1.9983633825512492e-07\n",
      "Operator 57: 2.529170887488222\n",
      "Operator 58: -1.90204411530141e-07\n",
      "Operator 59: 3.26458549122993\n",
      "Operator 60: -3.11362822703031\n",
      "Operator 61: -8.105815596985563e-08\n",
      "Operator 62: -1.7950115322673246\n",
      "Operator 63: -2.1226611013336338e-07\n",
      "Operator 64: -1.0172370298054343\n",
      "Operator 65: 1.569975403015178e-07\n",
      "Operator 67: -1.5813160089103984\n",
      "Operator 68: 3.064339963489725\n",
      "Operator 69: 1.737314350731305\n",
      "Operator 70: -1.9983633825512492e-07\n",
      "Operator 71: 2.7995881722647518\n",
      "Operator 72: -0.9299944477259512\n",
      "Operator 73: 3.26458549122993\n",
      "Operator 74: 1.9687245404932177\n",
      "Operator 75: -8.105815596985563e-08\n",
      "Operator 76: 2.3794038410695832\n",
      "Operator 77: -1.2973628470393874\n",
      "Operator 78: 2.1144225604613007\n",
      "Operator 79: -1.7427537925721\n",
      "Operator 80: 2.2736820523639114\n",
      "Operator 81: -1.866587272048225e-07\n",
      "Operator 82: 1.9375597834999074\n",
      "Operator 83: 3.2645853962583233\n",
      "Operator 84: -0.9299946478234806\n",
      "Operator 85: 2.7995881722647527\n",
      "Operator 86: 1.90204411530141e-07\n",
      "Operator 87: 1.8177672762936\n",
      "Operator 88: 3.11362822703031\n",
      "Operator 89: -1.4684488529796202\n",
      "Operator 90: 2.3794038410695832\n",
      "Operator 91: -1.8273254082559687\n",
      "Operator 92: 2.1144225604613007\n",
      "Operator 93: -2.273682052363916\n",
      "Operator 94: 1.8665872652526026e-07\n",
      "Operator 95: -1.9375597834999037\n",
      "Operator 96: -3.2645853962583216\n",
      "Operator 97: 0.9299946478234806\n",
      "Operator 98: -2.799588172264752\n",
      "Operator 99: -1.90204411530141e-07\n",
      "Operator 100: -1.8177672762936026\n",
      "Operator 101: -3.113628227030309\n",
      "Operator 102: 1.4684488529796207\n",
      "Operator 103: -2.379403841069583\n",
      "Operator 104: 1.8273254082559687\n",
      "Operator 105: -2.1144225604613016\n",
      "Operator 106: -1.5786155929917038\n",
      "Operator 107: -2.273682052363916\n",
      "Operator 108: 2.2736820523639123\n",
      "Operator 109: 1.6363382550087906\n",
      "Operator 114: 1.2004118277352664\n",
      "Operator 119: 1.5618886765464435\n",
      "Operator 121: 1.8536481838203105\n",
      "Operator 123: 2.2736820523639114\n",
      "Operator 124: 1.1802294795428442e-07\n",
      "Operator 125: 3.064339963489725\n",
      "Operator 126: -2.0641736634946564\n",
      "Operator 127: -1.9983633825512492e-07\n",
      "Operator 128: -2.7995881722647527\n",
      "Operator 129: 1.0590850024247305e-07\n",
      "Operator 130: -3.26458549122993\n",
      "Operator 131: 1.0607871463065992\n",
      "Operator 132: 8.105815596985563e-08\n",
      "Operator 133: 0.3995658211377967\n",
      "Operator 134: 2.1226611013336338e-07\n",
      "Operator 135: 1.6932750639275245\n",
      "Operator 136: -1.693275063927524\n",
      "Operator 138: 1.5494591880944273\n",
      "Operator 139: -1.549459188094428\n",
      "Operator 140: 1.5494591105837\n",
      "Operator 141: -1.5494591105836988\n",
      "Operator 143: 1.6612742615117444\n",
      "Operator 144: -1.6612742615117435\n",
      "Operator 145: 1.8803501778510026\n",
      "Operator 146: -1.8803501778510006\n",
      "Operator 147: 1.9715989134947178\n",
      "Operator 148: -1.6363382550087904\n",
      "Operator 153: -1.2004118277352671\n",
      "Operator 158: -1.561888676546443\n",
      "Operator 160: -1.8536481838203125\n",
      "Operator 161: 1.5813160089103984\n",
      "Operator 162: -0.7879576818658769\n",
      "Operator 163: -1.737314350731305\n",
      "Operator 164: 1.0634689752676554e-07\n",
      "Operator 165: -2.5291708874882275\n",
      "Operator 166: 0.9299944477259512\n",
      "Operator 167: -2.064173568523061\n",
      "Operator 168: -1.9687245404932177\n",
      "Operator 169: 5.1252486727470856e-08\n",
      "Operator 170: -1.7950115322673232\n",
      "Operator 171: 1.2973628470393863\n",
      "Operator 172: -0.5664119349858965\n",
      "Operator 173: 1.7427537925721\n",
      "Operator 174: 1.6363382550087906\n",
      "Operator 179: 1.2004118277352664\n",
      "Operator 184: 1.5618886765464435\n",
      "Operator 186: 1.8536481838203105\n",
      "Operator 187: -1.9327494863278059\n",
      "Operator 189: -1.63633825500879\n",
      "Operator 194: -1.2004118277352671\n",
      "Operator 199: -1.561888676546443\n",
      "Operator 201: -1.8536481838203125\n",
      "Total gradient norm: 23.486024534330365\n",
      "Operators under consideration (1):\n",
      "[130]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(-3.26458549122993)]\n",
      "Operator(s) added to ansatz: [130]\n",
      "Initial energy: -22.375284053874815\n",
      "Optimizing energy with indices [169, 188, 166, 173, 164, 94, 134, 130]...\n",
      "Starting point: [np.float64(0.4901254764438521), np.float64(-0.6553685359636564), np.float64(0.44314363106479154), np.float64(0.7010350187592747), np.float64(0.443143661711486), np.float64(0.5048173805966985), np.float64(0.6115719318015798), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -22.965602\n",
      "         Iterations: 14\n",
      "         Function evaluations: 24\n",
      "         Gradient evaluations: 24\n",
      "\n",
      "Current energy: -22.965602387385694\n",
      "(change of -0.5903183335108793)\n",
      "Current ansatz: [169, 188, 166, 173, 164, 94, 134, 130]\n",
      "coefficients: [np.float64(0.5447918834588108), np.float64(-0.6553685269365342), np.float64(0.32314124834482855), np.float64(0.7133577267549619), np.float64(0.41922163738961626), np.float64(0.504817357715603), np.float64(0.6381946419332903), np.float64(0.3582312495246916)]\n",
      "indices: [169, 188, 166, 173, 164, 94, 134, 130]\n",
      "On iteration 8.\n",
      "\n",
      "*** ADAPT-VQE Iteration 9 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 1.5786157053740182\n",
      "Operator 2: 3.064340040977695\n",
      "Operator 3: -3.3372424426722027\n",
      "Operator 5: -2.9338985926090686\n",
      "Operator 7: -1.1784720379683526\n",
      "Operator 8: 2.4339759288488714\n",
      "Operator 10: 1.5060536534079778\n",
      "Operator 12: 0.8675106878825347\n",
      "Operator 15: -2.2736820908587205\n",
      "Operator 17: -3.064340040977695\n",
      "Operator 18: 2.664214334961451\n",
      "Operator 20: 3.067558185024588\n",
      "Operator 21: -0.5948225112516744\n",
      "Operator 22: 1.1784720379683526\n",
      "Operator 23: -0.7829166434281047\n",
      "Operator 25: -0.32573431803775965\n",
      "Operator 27: -1.6932750152209977\n",
      "Operator 28: 1.6932750152209843\n",
      "Operator 30: -1.4872063237883824\n",
      "Operator 31: 1.4872063237883828\n",
      "Operator 32: -0.9083128691195204\n",
      "Operator 33: 1.4757418239419637\n",
      "Operator 34: 1.3134420765997592\n",
      "Operator 35: -1.7728686718823887\n",
      "Operator 36: 1.7728686718823843\n",
      "Operator 37: -1.9139487407123363\n",
      "Operator 38: 1.913948740712338\n",
      "Operator 39: -1.9792765894834163\n",
      "Operator 40: 1.5813159002328165\n",
      "Operator 41: -3.0643400409776937\n",
      "Operator 42: -1.7759803790930935\n",
      "Operator 44: -3.067558185024588\n",
      "Operator 45: -0.3570095470562734\n",
      "Operator 46: -1.1784720379683526\n",
      "Operator 47: -2.153975413305302\n",
      "Operator 48: 0.7646072722241688\n",
      "Operator 49: -2.268615179189961\n",
      "Operator 50: 1.503915524524673\n",
      "Operator 51: -2.0833275983354627\n",
      "Operator 52: 1.8126213928124741\n",
      "Operator 54: -3.064340040977699\n",
      "Operator 55: 3.337242442672201\n",
      "Operator 57: 2.933898592609064\n",
      "Operator 58: -1.2851180619154263\n",
      "Operator 60: -2.43397592884887\n",
      "Operator 62: -1.5060536534079798\n",
      "Operator 64: -0.8675106878825315\n",
      "Operator 67: -1.5813159002328163\n",
      "Operator 68: 3.064340040977701\n",
      "Operator 69: 1.7759803790930946\n",
      "Operator 71: 3.0675581850245854\n",
      "Operator 72: -0.6659929552331987\n",
      "Operator 74: 2.153975413305302\n",
      "Operator 75: -0.7646072722241688\n",
      "Operator 76: 2.268615179189961\n",
      "Operator 77: -1.503915524524673\n",
      "Operator 78: 2.0833275983354618\n",
      "Operator 79: -1.8126213928124741\n",
      "Operator 80: 2.273682090858717\n",
      "Operator 82: 2.0488827807876\n",
      "Operator 83: 3.3372424426722027\n",
      "Operator 84: -0.539368515290079\n",
      "Operator 85: 2.313348679395283\n",
      "Operator 87: -1.032057905979229\n",
      "Operator 88: 2.6981080596350955\n",
      "Operator 89: -1.6235930331144424\n",
      "Operator 90: 2.268615179189961\n",
      "Operator 91: -1.8744906862336843\n",
      "Operator 92: 2.0833275983354618\n",
      "Operator 93: -2.2736820908587205\n",
      "Operator 95: -2.048882780787598\n",
      "Operator 96: -3.337242442672201\n",
      "Operator 97: 0.539368515290079\n",
      "Operator 98: -2.3133486793952844\n",
      "Operator 99: -1.2851180619154263\n",
      "Operator 100: 0.27845986837029146\n",
      "Operator 101: -2.698108059635096\n",
      "Operator 102: 1.6235930331144424\n",
      "Operator 103: -2.268615179189961\n",
      "Operator 104: 1.8744906862336856\n",
      "Operator 105: -2.0833275983354627\n",
      "Operator 106: -1.5786157053740077\n",
      "Operator 107: -2.2736820908587196\n",
      "Operator 108: 2.273682090858716\n",
      "Operator 109: 1.6363382000791216\n",
      "Operator 114: 0.8956295365818815\n",
      "Operator 115: -0.7909847474260548\n",
      "Operator 116: -0.366110747151495\n",
      "Operator 117: 0.9294775348394938\n",
      "Operator 119: 1.6965898809988174\n",
      "Operator 121: 1.8941169679815912\n",
      "Operator 123: 2.273682090858717\n",
      "Operator 125: 3.064340040977699\n",
      "Operator 126: -2.6642143349614527\n",
      "Operator 128: -3.0675581850245854\n",
      "Operator 131: 0.7829166434281043\n",
      "Operator 133: 0.32573431803775943\n",
      "Operator 135: 1.6932750152209943\n",
      "Operator 136: -1.6932750152209937\n",
      "Operator 138: 1.487206323788378\n",
      "Operator 139: -1.4872063237883772\n",
      "Operator 140: 1.20444557322811\n",
      "Operator 141: 1.562224702057788\n",
      "Operator 142: -1.0485576845944282\n",
      "Operator 143: 1.7728686718823878\n",
      "Operator 144: -1.7728686718823858\n",
      "Operator 145: 1.9139487407123366\n",
      "Operator 146: -1.9139487407123357\n",
      "Operator 147: 1.9792765894834166\n",
      "Operator 148: -1.6363382000791211\n",
      "Operator 153: -0.8956295365818817\n",
      "Operator 156: -0.9294775348394937\n",
      "Operator 158: -1.696589880998817\n",
      "Operator 160: -1.8941169679815928\n",
      "Operator 161: 1.5813159002328163\n",
      "Operator 162: -0.7879577552550093\n",
      "Operator 163: -1.7759803790930946\n",
      "Operator 165: -2.9338985926090686\n",
      "Operator 166: 0.6659929552331987\n",
      "Operator 167: -0.7879514133368323\n",
      "Operator 168: -1.9431113177974253\n",
      "Operator 169: 0.6104074517415878\n",
      "Operator 170: -1.1357656546559904\n",
      "Operator 171: 1.503915524524674\n",
      "Operator 172: -0.4015311131296801\n",
      "Operator 173: 1.8126213928124741\n",
      "Operator 174: 1.6363382000791216\n",
      "Operator 179: 0.6754243214664566\n",
      "Operator 180: -0.5288691878822271\n",
      "Operator 181: -0.790984747426055\n",
      "Operator 182: 1.1642801549679254\n",
      "Operator 184: 1.6965898809988174\n",
      "Operator 186: 1.8941169679815912\n",
      "Operator 187: -1.932749477042949\n",
      "Operator 189: -1.6363382000791207\n",
      "Operator 194: -0.6754243214664566\n",
      "Operator 197: -1.1642801549679254\n",
      "Operator 199: -1.6965898809988165\n",
      "Operator 201: -1.894116967981593\n",
      "Total gradient norm: 22.209641724501587\n",
      "Operators under consideration (1):\n",
      "[83]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(3.3372424426722027)]\n",
      "Operator(s) added to ansatz: [83]\n",
      "Initial energy: -22.965602387385694\n",
      "Optimizing energy with indices [169, 188, 166, 173, 164, 94, 134, 130, 83]...\n",
      "Starting point: [np.float64(0.5447918834588108), np.float64(-0.6553685269365342), np.float64(0.32314124834482855), np.float64(0.7133577267549619), np.float64(0.41922163738961626), np.float64(0.504817357715603), np.float64(0.6381946419332903), np.float64(0.3582312495246916), np.float64(0.0)]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -23.586770\n",
      "         Iterations: 14\n",
      "         Function evaluations: 22\n",
      "         Gradient evaluations: 22\n",
      "\n",
      "Current energy: -23.586770166970936\n",
      "(change of -0.6211677795852424)\n",
      "Current ansatz: [169, 188, 166, 173, 164, 94, 134, 130, 83]\n",
      "coefficients: [np.float64(0.5469163977350211), np.float64(-0.6797739564797199), np.float64(0.30603096639012467), np.float64(0.7138721157965077), np.float64(0.30482938773898194), np.float64(0.5637630959042474), np.float64(0.6392917758168098), np.float64(0.3647985478641288), np.float64(-0.36895032618864654)]\n",
      "indices: [169, 188, 166, 173, 164, 94, 134, 130, 83]\n",
      "On iteration 9.\n",
      "\n",
      "*** ADAPT-VQE Iteration 10 ***\n",
      "\n",
      "Creating list of up to 1 operators ordered by gradient magnitude...\n",
      "\n",
      "Non-Zero Gradients (tolerance E-8):\n",
      "Operator 0: 1.2771531336376496\n",
      "Operator 2: 2.337556675027411\n",
      "Operator 4: 1.3120856305259405\n",
      "Operator 5: -3.2766170172873244\n",
      "Operator 7: -1.1190779106737463\n",
      "Operator 8: 2.4090534900571683\n",
      "Operator 10: 1.4943112402110899\n",
      "Operator 12: 0.8612731901158632\n",
      "Operator 15: -1.6128420180753003\n",
      "Operator 17: -2.6346650520442356\n",
      "Operator 18: 0.9140282598704836\n",
      "Operator 19: -0.9780850834194794\n",
      "Operator 20: 3.3420264347752573\n",
      "Operator 21: -0.5960256646545028\n",
      "Operator 22: 1.1190779106737465\n",
      "Operator 23: -0.7733121713030588\n",
      "Operator 25: -0.3228374974564231\n",
      "Operator 27: -1.8067078971021964\n",
      "Operator 28: 1.8067078971021848\n",
      "Operator 29: -1.103076606140473\n",
      "Operator 30: 1.5989996227894554\n",
      "Operator 31: 1.145175485504217\n",
      "Operator 32: -0.8565979746488317\n",
      "Operator 33: 1.4519183312736497\n",
      "Operator 34: 1.3331386938696652\n",
      "Operator 35: -1.7767860190390041\n",
      "Operator 36: 1.7767860190389988\n",
      "Operator 37: -1.9152175641776648\n",
      "Operator 38: 1.915217564177665\n",
      "Operator 39: -1.9795709718692258\n",
      "Operator 40: 1.7272741660660478\n",
      "Operator 41: -2.6346650520442356\n",
      "Operator 42: 0.4211905406579187\n",
      "Operator 43: -1.3120856305259405\n",
      "Operator 44: -2.472706857261882\n",
      "Operator 45: -0.7835564714374186\n",
      "Operator 46: -1.1190779106737458\n",
      "Operator 47: -2.1971215897285172\n",
      "Operator 48: 0.7894521371405916\n",
      "Operator 49: -2.264498239552078\n",
      "Operator 50: 1.5115704076942584\n",
      "Operator 51: -2.0821377647035693\n",
      "Operator 52: 1.81529544246205\n",
      "Operator 54: -2.3375566750274177\n",
      "Operator 55: 1.1167590434852892\n",
      "Operator 57: 3.276617017287322\n",
      "Operator 58: -1.2982940596067778\n",
      "Operator 60: -2.4090534900571674\n",
      "Operator 62: -1.4943112402110916\n",
      "Operator 64: -0.8612731901158596\n",
      "Operator 67: -1.7272741660660478\n",
      "Operator 68: 2.6346650520442405\n",
      "Operator 69: -1.0979704182532775\n",
      "Operator 71: 2.472706857261882\n",
      "Operator 72: -0.37674429239283147\n",
      "Operator 74: 2.197121589728517\n",
      "Operator 75: -0.7894521371405916\n",
      "Operator 76: 2.2644982395520783\n",
      "Operator 77: -1.5115704076942584\n",
      "Operator 78: 2.0821377647035684\n",
      "Operator 79: -1.81529544246205\n",
      "Operator 80: 2.1798623818646368\n",
      "Operator 81: -0.8176688257068039\n",
      "Operator 82: 2.1600128767712805\n",
      "Operator 84: -0.37803954386790817\n",
      "Operator 85: 2.4912903001132554\n",
      "Operator 87: -1.0521692346170446\n",
      "Operator 88: 2.6844415131254022\n",
      "Operator 89: -1.6293386842872355\n",
      "Operator 90: 2.2644982395520783\n",
      "Operator 91: -1.8762913573912907\n",
      "Operator 92: 2.0821377647035684\n",
      "Operator 93: -2.179862381864639\n",
      "Operator 94: 0.817668825706804\n",
      "Operator 95: -2.160012876771277\n",
      "Operator 96: -1.1167590434852892\n",
      "Operator 97: -0.7941914096043521\n",
      "Operator 98: -2.4912903001132567\n",
      "Operator 99: -1.2982940596067765\n",
      "Operator 100: 0.3474133095302318\n",
      "Operator 101: -2.684441513125402\n",
      "Operator 102: 1.6293386842872355\n",
      "Operator 103: -2.264498239552078\n",
      "Operator 104: 1.8762913573912907\n",
      "Operator 105: -2.0821377647035693\n",
      "Operator 106: -1.2771531336376376\n",
      "Operator 107: -2.179862381864639\n",
      "Operator 108: 2.1798623818646368\n",
      "Operator 109: 1.7665446150913133\n",
      "Operator 111: 1.2154376691126727\n",
      "Operator 112: -0.7704009181886518\n",
      "Operator 113: -0.6305462353427321\n",
      "Operator 114: 0.4868188502088896\n",
      "Operator 115: -0.7659632356398418\n",
      "Operator 116: -0.35164125048944994\n",
      "Operator 117: 0.9693499936185607\n",
      "Operator 119: 1.7014658957244055\n",
      "Operator 121: 1.8956545474300999\n",
      "Operator 123: 1.6128420180752978\n",
      "Operator 125: 2.63466505204424\n",
      "Operator 128: -3.3420264347752555\n",
      "Operator 131: 0.7733121713030586\n",
      "Operator 133: 0.322837497456423\n",
      "Operator 135: 1.8067078971021933\n",
      "Operator 136: -1.8067078971021922\n",
      "Operator 137: 1.345472249346044\n",
      "Operator 138: 1.443046032895118\n",
      "Operator 139: -0.8472952955457085\n",
      "Operator 140: 1.1491126004549477\n",
      "Operator 141: 1.5941452053501224\n",
      "Operator 142: -1.0911274438582592\n",
      "Operator 143: 1.776786019039003\n",
      "Operator 144: -1.7767860190390001\n",
      "Operator 145: 1.9152175641776652\n",
      "Operator 146: -1.915217564177663\n",
      "Operator 147: 1.9795709718692265\n",
      "Operator 148: -1.766544615091314\n",
      "Operator 150: -1.2154376691126716\n",
      "Operator 153: -0.4868188502088899\n",
      "Operator 156: -0.9693499936185607\n",
      "Operator 158: -1.701465895724405\n",
      "Operator 160: -1.8956545474301014\n",
      "Operator 161: 1.7272741660660478\n",
      "Operator 162: -0.4901405769648871\n",
      "Operator 163: 1.0979704182532772\n",
      "Operator 164: -0.5627480718193374\n",
      "Operator 165: -2.424311574247673\n",
      "Operator 166: 0.27874650707144205\n",
      "Operator 167: -0.9174686912440984\n",
      "Operator 168: -1.9717261143279678\n",
      "Operator 169: 0.6461389924451939\n",
      "Operator 170: -1.1139238934052447\n",
      "Operator 171: 1.5115704076942584\n",
      "Operator 172: -0.39539649880504896\n",
      "Operator 173: 1.81529544246205\n",
      "Operator 174: 1.766544615091314\n",
      "Operator 176: 0.9964686077113384\n",
      "Operator 177: -0.3304217508004651\n",
      "Operator 178: -0.7704009181886555\n",
      "Operator 179: 0.4904775007502016\n",
      "Operator 180: -0.6279699390371192\n",
      "Operator 181: -0.7659632356398425\n",
      "Operator 182: 1.1843510963537698\n",
      "Operator 184: 1.701465895724406\n",
      "Operator 186: 1.8956545474300999\n",
      "Operator 187: -1.955539816840016\n",
      "Operator 189: -1.7665446150913133\n",
      "Operator 191: -0.9964686077113373\n",
      "Operator 194: -0.4904775007502018\n",
      "Operator 197: -1.1843510963537698\n",
      "Operator 199: -1.701465895724405\n",
      "Operator 201: -1.8956545474301014\n",
      "Total gradient norm: 20.563516104430477\n",
      "Operators under consideration (1):\n",
      "[20]\n",
      "Corresponding gradients (ordered by magnitude):\n",
      "[np.float64(3.3420264347752573)]\n",
      "Operator(s) added to ansatz: [20]\n",
      "Initial energy: -23.586770166970936\n",
      "Optimizing energy with indices [169, 188, 166, 173, 164, 94, 134, 130, 83, 20]...\n",
      "Starting point: [np.float64(0.5469163977350211), np.float64(-0.6797739564797199), np.float64(0.30603096639012467), np.float64(0.7138721157965077), np.float64(0.30482938773898194), np.float64(0.5637630959042474), np.float64(0.6392917758168098), np.float64(0.3647985478641288), np.float64(-0.36895032618864654), np.float64(0.0)]\n",
      "         Current function value: -24.180861\n",
      "         Iterations: 18\n",
      "         Function evaluations: 108\n",
      "         Gradient evaluations: 93\n",
      "\n",
      "Current energy: -24.180861458247364\n",
      "(change of -0.5940912912764276)\n",
      "Current ansatz: [169, 188, 166, 173, 164, 94, 134, 130, 83, 20]\n",
      "coefficients: [np.float64(0.5820854539485039), np.float64(-0.6957098479843011), np.float64(0.18800555674560898), np.float64(0.7227691171394697), np.float64(0.18650718350944642), np.float64(0.5998425836106855), np.float64(0.6581104114186396), np.float64(0.45773664464666747), np.float64(-0.4637302289985455), np.float64(-0.38288360790367576)]\n",
      "indices: [169, 188, 166, 173, 164, 94, 134, 130, 83, 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2492: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  opt_result = minimize_bfgs(\n",
      "/Users/benjamindalfavero/Documents/phd/wellcome/ceo-adapt-vqe/adaptvqe/algorithms/adapt_vqe.py:2507: UserWarning: Optimizer did not succeed. Message: Desired error not necessarily achieved due to precision loss.\n",
      "  warn(f\"Optimizer did not succeed. Message: {opt_result.message}\")\n"
     ]
    }
   ],
   "source": [
    "# Now go to the larger size.\n",
    "new_l = 4 * l\n",
    "j_xy = 1\n",
    "j_z = 1\n",
    "h = XXZHamiltonian(\n",
    "    j_xy, j_z, new_l,\n",
    "    store_ref_vector=False,\n",
    "    diag_mode=\"quimb\", max_mpo_bond=max_mpo_bond, max_mps_bond=dmrg_mps_bond\n",
    ")\n",
    "dmrg_energy = h.ground_energy\n",
    "exact_energy = h.ground_energy\n",
    "print(f\"Got DMRG energy {dmrg_energy:4.5e}\")\n",
    "\n",
    "h_of = h.operator\n",
    "h_cirq = of.transforms.qubit_operator_to_pauli_sum(h_of)\n",
    "h_qiskit = cirq_pauli_sum_to_qiskit_pauli_op(h_cirq)\n",
    "\n",
    "tiled_pool = TiledPauliPool(n=new_l, source_ops=source_ops)\n",
    "num_ops = len(tiled_pool.operators)\n",
    "print(f\"Tiled pool has {num_ops} operators.\")\n",
    "\n",
    "tn_adapt = TensorNetAdapt(\n",
    "    pool=tiled_pool,\n",
    "    custom_hamiltonian=h,\n",
    "    verbose=True,\n",
    "    threshold=10**-5,\n",
    "    max_adapt_iter=30,\n",
    "    max_opt_iter=10000,\n",
    "    sel_criterion=\"gradient\",\n",
    "    recycle_hessian=False,\n",
    "    rand_degenerate=True,\n",
    "    max_mpo_bond=max_mpo_bond,\n",
    "    max_mps_bond=adapt_mps_bond\n",
    ")\n",
    "tn_adapt.initialize()\n",
    "nq = tn_adapt.n\n",
    "\n",
    "circuits = []\n",
    "adapt_energies = []\n",
    "for i in range(10):\n",
    "    print(f\"On iteration {i}.\")\n",
    "    tn_adapt.run_iteration()\n",
    "    data = tn_adapt.data\n",
    "    ansatz_circuit = pool.get_circuit(tn_adapt.indices, tn_adapt.coefficients)\n",
    "    print(\"coefficients:\", tn_adapt.coefficients)\n",
    "    print(\"indices:\", tn_adapt.indices)\n",
    "    # Prepare the HF reference state, then add the Ansatz circuit.\n",
    "    q = QuantumRegister(nq)\n",
    "    circuit = QuantumCircuit(q)\n",
    "    ref_circuit = neel_circuit(nq, start_zero=False)\n",
    "    circuit = circuit.compose(ref_circuit)\n",
    "    circuit = circuit.compose(ansatz_circuit)\n",
    "    circuit.measure_all()\n",
    "    circuits.append(circuit)\n",
    "    adapt_energies.append(tn_adapt.energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cc70396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "16\n",
      "25\n",
      "32\n",
      "41\n",
      "48\n",
      "57\n",
      "66\n",
      "73\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "for circuit in circuits:\n",
    "    print(circuit.depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "572ff26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Energy error')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGwCAYAAACzXI8XAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAP8JJREFUeJzt3Qd01FXexvEnPZQk9NBJAkjvLXSiAjZsWAClCqyCYFnbWlZ93cV1ddfOIqKIoCAWVGwoUkR6771DAoSSQiCEJPOeewMRpE5IMu37OWdO8v/PJLne8SQPv9v8HA6HQwAAAB7I39UNAAAAyCuCDAAA8FgEGQAA4LEIMgAAwGMRZAAAgMciyAAAAI9FkAEAAB4rUF4uOztb8fHxCgsLk5+fn6ubAwAALoPZ5i41NVUVK1aUv7+/7wYZE2KqVKni6mYAAIA82L17typXruy7QcZUYk53RHh4uKubAwAALkNKSootRJz+O+6zQeb0cJIJMQQZAAA8y6WmhTDZFwAAeCyCDAAA8FguDzIZGRl66qmnFBgYqB07duTez8zM1JgxYxQXF6err75azZo108CBA3Xw4EGXthcAALgPlwYZE1w6duyohIQEZWVlnfXcvn37NGzYML355puaMWOG5s2bp+3bt+uOO+5wWXsBAIB7cWmQOXr0qMaPH6/+/fuf81xwcLAGDBighg0b2uuQkBA98MADmj17tg0+AAAALl21VL9+fftxz5495zxXrlw5vfvuu2fdCw0NtR9PnDhRSC0EAADuzKOWX8+fP18tWrRQVFTUBV9jQs6ZQcesQwcAAN7J5ZN9L5eZ5PvBBx/onXfeuejrXn75ZUVEROQ+2NUXAADv5RFBxqxg6tmzp/7xj3+oZcuWF33t3/72NyUnJ+c+zI6+AADAOwV6wqGPffv21bXXXmuXX1+KmRRsHgAAwPu5fUVm6NChqlq1qp588kl7PX36dG3bts3VzQIAAG7ArYOM2Shvw4YN6t69u5YsWWIfkydP1q5du1zdNAAA4OtDS2ZX3y5duigpKcle9+jRw07O/fzzz7V27Vq98sor9r5ZqXSmXr16ydWysx2aseGArq0b6eqmAADgs1waZMymd7NmzTrvc/Xq1ZPD4ZA7Mu165us1mrhol4ZfU1OPXFvzkqdzAgAAHxtaclcmtESXKWo/f+vXzXr9l01uG7oAAPBmBJk8Gtyhup69sY79/K0ZW/RfwgwAAIWOIHMFBraPyQ0zb8/Yotd+3khlBgCAQkSQyYcw8/eb6trP3525Vf+eRpgBAKCwEGTywYB20XqhW06Y+d+srfrXTxuozAAAUAgIMvmkX9to/d8t9ezn783eppd/JMwAAFDQCDL5qE/rKL10KsyM/m2b/vn9eiozAAAUIIJMPuvdOkr/uLW+/XzM79v10neEGQAACgpBpgDcG1tNI25rYD//cO52vTh1HZUZAAAKAEGmgPRqVVX/uj0nzHw0b4de+HYtYQYAgHxGkClAPVpW1b+7N5Q5vWDc/J36+zeEGQAA8hNBpoDd1aKKXjkVZsYv2KnnvlljD5wEAABXjiBTCO5qXkWv3tHIhpkJC3bpWcIMAAD5giBTSO5oVln/uTMnzHy6cJee+Xo1lRkAAK4QQaYQ3d60sv57VyP5+0kTF+3W374izAAAcCUIMoXstiaV9frdjW2Y+WzJbj355SoqMwAA5BFBxgVuaVxJb/RoYsPM50v36IkvVymLCcAAADgt0PkvQX64uVFF+Ul6+LMV+mLpHmU7HHZCcIBJNwAA4LIQZFyoW6OK8vfz0/BJy/XVsr2SQ3r1TsIMAACXi6ElF7uxYQW93bOJrcR8tXyv/jp5BcNMAABcJioybuCGBhXsMNOwicv19Yp4U5ixS7UDA8iZAABcDH8p3cT1DSronV5NFejvp29WxOuRySuVmZXt6mYBAODWCDJu5Lr65TXynqYKCvDT1JXxeuizFYQZAAAugiDjZrrUM2GmmQ0z369K0EOTVugklRkAAM6LIOOGOteN1Kh7myk4wF/fr07Q8InLCTMAAJwHQcZNXVMnUqN6N7Vh5sc1+/Tgp8uUkcmcGQAAzkSQcWNX147Ue32aKTjQX9PW7ifMAADwJwQZNxdXq5xG984JMz+v268hn1CZAQDgNIKMB+hUq5zG9GmukEB/TV9vwsxSncjMcnWzAABwOYKMh+hwVVmN6Xs6zBzQAxOWEWYAAD6PIONB2tcsqw/7tVBokL9mbDig+8cvVfpJKjMAAN9FkPEwbWuU0Yd9c8LMzI2J+gthBgDgwwgyHqhNjTIa26+ligQFaPamRA36eAmVGQCATyLIeKjW1UtrbP8WNszM2XyQMAMA8EkEGQ8WG1NaH/VvoaLBOWFm4LglOp7BnBkAgO8gyHi4VjGlNW5ASxULDtDvWw7qvnGLCTMAAJ9BkPECLaJK5YaZeVsPacBHi3UsI9PVzQIAoMARZLxE86hS+vi+lioeEqj52wgzAADfQJDxIs2q5VRmTJhZsO2w+o1drLQTVGYAAN6LIONlmlUraSszYSGBWrT9sPoTZgAAXowg44WaVi2p8QNbKSw0UIt2mMrMIh2lMgMA8EIEGS/VuEoJTbgvJ8ws3nFEfT9cpNT0k65uFgAA+Yog48UaVSmhTwa2UnhooJbuJMwAALwPQcbLNaxcQp8OilVEkSAt25WkPh8uUgqVGQCAlyDI+ID6lSJsZaZE0SAt35Wk3h8sUvJxhpkAAJ6PIOODYWbl7iT1+WAhYQYA4PEIMj6kXsUIfTowViVNmNmTrN4mzByjMgMA8FwEGR9Tt2K4nTNTqliwVu1J1j0fLFDSsQxXNwsAgDwhyPigOhXCNXFQrEoXC9aavSm6Z8xCHU4jzAAAPA9BxkfVKh+miYNjVaZ4sNbGp6jL67/p57X7XN0sAACcQpDxYVdFhtnKTPWyxXTw6AkNHr9UD09ariNUZwAAHoIg4+NqRobp++HtdX/H6vL3k75eEa/Or/+maVRnAAAegCADhQYF6Knra+urIW1Vo1xxW535y/ilGj6R6gwAwL0RZHDW+UzfDWunBzrlVGe+XWmqM7P10xrmzgAA3BNBBudUZ568Lqc6U9NWZzJ0/4SlGjZxOSubAABuhyCDC1Znpg5rpyGnqjNTV8ari63OJNBjAAC3QZDBRaszT1xXW1OGtNVVkaerM8v04KfLqM4AANwCQQaX1OhUdWZoXHUF+Pvpu1UJ6vzf2fpxNdUZAIBrEWRwWUICA/R4V1OdaaNakWE6lJahBz5ZpqGfLtOhoyfoRQCASxBk4JSGlUvo22FtNezqGrY68/2qBLsr8A9UZwAALkCQQZ6qM3/tUktfD2mbW50ZYqoznyyze9AAAFBYCDLIswaVI86uzqzOqc58tyqeXgUAFAqCDPKlOvPN0LaqXT7MrmZ68NPlGvLJUqozAIACR5BBvqhfKULfPthOw6+pqUB/P/2wep9d2WT2n3E4HPQyAKBAEGSQb4ID/fVo56v09anqzJFjJ+2OwGb+TGIqc2cAAPmPIIMCq848dKo68+OafXZXYHN2E9UZAEB+IsigwKozj3S+St882FZ1KoTb6ow5TfuBCVRnAAD5hyCDAlWvYoSdCPzwtTnVmZ/W7rMnan+zYi/VGQCA5weZjIwMPfXUUwoMDNSOHTvOef69995Ts2bN1LZtW914443au3evS9qJK6vOPHztH9WZpGMn9dCkFfrL+KU6kJpO1wIAPDPImODSsWNHJSQkKCsr65znv/rqK7344ouaNm2a5s6dq1atWummm25Sdna2S9qLK6/OfPtgWz1y7VW2OvPzuv123xmqMwCAvPJzuHD25Zo1axQaGqo9e/YoLi5O27dvV1RUVO7zTZs2VdeuXfXyyy/b6+TkZJUpU8YGnG7dul3Wz0hJSVFERIT92vDw8AL7b4Fz1sWn6PEvVmptfIq97lw3Uv+8rb7KhYXSlQAAXe7fb5dWZOrXr68aNWqc97nDhw9r+fLlat68ee498x901VVXafr06YXYShSEuhXD7TJts1w7KMBPv6zbr87//U1fL2fuDADAg+bIXIipzhiRkZFn3S9fvnzuc+dz4sQJm+LOfMA9BQX42w30zFLt+pXClXz8pB7+bIUGfbxUB1KYOwMA8OAgc+zYMfsxJCTkrPvm+vRz52OGoUzl5vSjSpUqBd5WXBkzAXjKkLZ6rEtOdWb6+v3q/PpvmrJ8DyubAACeGWSKFi2aW2E5k7k+/dz5/O1vf7Pjaacfu3fvLvC2In+qMw9eXVNTh/1RnXnks5Ua9PES7ac6AwDwtCATExNjP+7fv/+s+/v27ct97nxMxcZMCjrzAc9Ru/yfqzMH7JlNXy6lOgMA8KAgU7JkSTVp0kRLly7NvWfmu2zatEnXXnutS9uGwqnOfDesvRpUilBKeqb++vlKDRxHdQYA4CFBxnj22Wc1btw4HTp0yF6/9dZbdqXTDTfc4OqmoRDUKh+mKUPa6PGutRQc4K9fN+RUZ76gOgMAOCVQLt7Vt0uXLkpKSrLXPXr0sJNzP//8c3t9++2368CBA+rcubPdb8ZUaaZOnSp/f7fOX8hHgQH+GhpXQ9fWibT7zqzak6zHPl+pH1YnaMRtDVQ+gn1nAMCXuXRDvMLAhnjeIzMrW6PnbNMbv2xWRla2wkID9feb6uqOZpXl5+fn6uYBAHxtQzzA2erMkE419P3wdmpUOUKp6Zl6/ItVGvDRYu1LZt8ZAPBFBBl4nJqRYfrygTZ68rradu7MzI2J9kTtyUt2s+8MAPgYggw8tjrzQKfqOdWZKiVsdeaJL1bpr5NXKivbq0dLAQBnIMjA86sz97e21RlzovZXy/fq0ckr7HwaAID3I8jAa6oz7/RqasPMNyvi9cjklYQZAPABBBl4jevql9fIe5raHYGnrozXQ59RmQEAb0eQgVfpUs+EmWY2zHy/KkEPTVqhkwwzAYDXIsjA63SuG6lR9zazK5q+X52g4ROXE2YAwEsRZOCVrqkTqVG9m9ow8+OafXrw02XKyGQCMAB4G4IMvNbVtSP1Xp9mCg7017S1+wkzAOCFCDLwanG1yml075ww8/O6/RryCZUZAPAmBBl4vU61yun9Ps1tmJm+3oSZpTqRmeXqZgEA8gFBBj6h41VlNaZPc4XYMHNAD0xYRpgBAC9AkIHP6HBVWX3Qt4UNMzM2HND945cq/SSVGQDwZAQZ+JR2Ncvow34tFBqUc9jk/RMIMwDgyQgy8Dlta/wRZmZtTNRgKjMA4LEIMvBJbaqX0dh+LVUkKEC/bUrUoI+XMMwEAB6IIAOf1bp6aX3Uv4WKBgdozuaDGjhuiY5nMGcGADwJQQY+rVWMCTMtbZj5fctBDfx4MWEGADwIQQY+r2V0KY0b0FLFggM0d8shDfhosY5lZPp8vwCAJyDIAJJaRJXSx/e1VPGQQM3fRpgBAE9BkAFOaVYtpzJjwsyCbYfVb+xipZ2gMgMA7owgA5yhWbWStjITFhKoRdsPqz9hBgDcGkEG+JOmVUtq/MBWCgsN1KIdpjKzSEepzACAWyLIAOfRuEoJTbgvJ8ws3nFEfT9cpNT0k/QVALgZggxwAY2qlNAnA1spPDRQS3cSZgDAHRFkgItoWNmEmVhFFAnSsl1J6vPhIqVQmQEAt0GQAS6hQeUIW5kxYWb5riT1/mCRko8zzAQA7oAgA1yG+pVywkyJokFauTtJfT5YSJgBADdAkAGcCDOfDoxVSRNm9iSrtwkzx6jMAIArEWQAJ9StGK5PB8WqVLFgrdqTrHs+WKCkYxn0IQC4CEEGcFKdCibMtLJhZs3eFN0zZiFhBgBchCAD5EHt8uGaOChWpYsFa218inq9v1BH0qjMAEBhI8gAeVSrfJgmDo5VmeLBWpeQol5jFuowYQYAChVBBrgCV0WG2cpMmeIhWm/CzPsLCDMAUIgIMsAVqhkZpkmDY1U2LEQb9qXaMHPo6An6FQAKAUEGyAc1yhW3YaZcbphZqIOEGQAocAQZIJ9UL5sTZiLDQ7Rxf6p6jl6gxFQqMwBQkAgyQD6KsWGmtcqHh2rzgaPq+f4CHUhNp48BoIAQZIB8Fl2mmK3MVIgI1RYTZkYv0IEUwgwAFASCDFAAos4IM1sT09TDVGYIMwCQ7wgyQAGpVjonzFSMCNU2E2ZGL9B+wgwA5CuCDFDgYaa1KpUoom0Hc8LMvmSGmQDAZUFm1apVWrt2bb41APB2VUsXtZUZE2a22zAzXwnJx13dLADwzSDTuHFjvf766wXTGsBLVSmVE2YqlyyiHYeO2cpMfBJhBgAKPci0a9dOY8aMueIfDPhqmKlSqoh2ngozewkzAFC4QaZ+/fqKj48/73M333zzlbUG8HKVS5ow01pVSxXVrsMmzMzXniPHXN0sAPBYgc5+QVhYmNq0aaNrrrlGlStXVkBAQO5za9asye/2AV7HzJUxlRmzWd7pyow5eNJUbAAAzvFzOBwOZ76gZMmSdp7M+axcuVKHDx+WO0lJSVFERISSk5MVHh7u6uYAucyEX7NZnpkzczrcEGYAwLm/34F5mSMzderU8z7Xs2dPZ78d4LMqRJjw0tpWZnJWM+VUZswqJwBAAVVkPA0VGbg7s0meqcyYfWbM5nkTB8fa/WcAwJelXGZFJk8b4u3cuVPDhw9XXFycfZjPzT0AzosMD7XDSjFliyk+Od1WZnYcTKMrAeAyOB1kZs2apdq1a2vOnDkqU6aMffz++++qU6eOZs+e7ey3AyCp3KkwU71sMSUkp+uWd+dq+rr99A0A5PfQklmx9OKLL6pz585n3Z8+fbqee+45zZ8/X+6EoSV4ksTUE7pv3GKt2pNsrwd3iNHjXWspKIDTRAD4lpSCGloyuefPIca49tpr7XMA8q5sWIg+v7+1+reNstejf9umu96bz8Z5AJBfQSYtLU0HDx48535iYqKOHWNjL+BKhQQG6Plu9TTq3qYKCw3U8l1JuuHNOfp1PUNNAHDFy6/79u2rZs2aqX///qpevbq9t2XLFo0bN85O+gWQP66rX0H1KkZo6KfL7FDTfeOWMNQEAPmx/Hr06NEaMWKEdu3aZa+rVq2qZ555RoMGDZK7YY4MPN2JzCz968cNGjt3h71uWrWE3u7V1G6iBwDe6nL/fjsdZMw39vPzs0cVHD161N4rXry43BVBBt7ipzUJevyLVUpNz1SJokH6z52NdE2dSFc3CwA8a7JviRIl1L1799wA484hBvC2oabvh7VXw8oRSjp20g41vfzDep3MynZ10wDAZZwOMi1atNDPP/9cMK0BcFHm+AKzqqlfm5xVTe/9tk13vzdf8UnH6TkAPsnpIFOrVi2lpqae97nBgwfnR5sAXGJV0ws3/7GqaZlZ1fTWHM3YwKomAL7H6VVLDRs2VKdOnXTrrbeqcuXKCggIyH3O7PALoPCGmupWyFnVtHpvsgZ8tER/6Rijx7qwgR4A3+H0ZN8iRYqofPny531u//79breXDJN94Qurml7+YYM+mpezqqlZtZJ6u2cTVWRVEwAPdrl/v52uyMTGxmrmzJnnfc4cIAnANUNNraJL6YkvVmnpziN2qOn1uxorrnY53g4AXs3pOTIDBw7UDz/8cN7nLhRwABS86xtU0HfD26lBpZxVTf0/Wmz3n2FVEwBv5nSQMTv6Ll26tGBaA+CKVCtdTF880Fp9W1ez16Nmb1XP0QtY1QTAazkdZDp06GBPuT4fd5sfA/jqUNOLt9TXyHuaKiwkUEt2HtGNb83RzA0HXN00AHCPfWRWr1593uduuumm/GgTgHxwwxlDTUcYagLgpZye7BsfH2+XXzdu3Pic5dcbNmzI7/bpxIkTeuqppzRjxgy7q3B6erq9vu222/L9ZwHeOtQ04vv1Gjd/px1qWrLjsN7u1UQVIjirCYAPBhmzq+/NN9+ce52HMyed8o9//ENff/21VqxYYZdhLV++3K6cWrRokRo1alSgPxvwpqGmVjGl9eQXq+xQ0w1vztF/726suFqsagLgY0HGDB+9//77533ukUceUX4zAcYMZ5kQYzRp0sR+bio0BBnAuaGmehXD7QZ6a/amqP/YxXqgU3X9tfNVCgxwepQZANyC07+9LhRijNdff135zRxQOWfOHO3atcteT5s2TYmJiYqM5NRfIC9DTV8+0CZ3VdP/Zm1Vz/cXKCGZs5oA+EhFxvjss880cuRIZWZmau7cuXrppZcUFRWl3r1753sD+/XrZ1dDmaMRKlSooE2bNumOO+7QXXfddcE5NeZx5s6AAM4damoZXVpPfrlKi3eYVU2/6793NVInhpoAeHtF5r333tNjjz1mh3WOH8/5V9ztt9+uKVOm6M0338z3Bo4ZM0b/+te/7N4169ev17Jly+wcGX//8zf95ZdftkNPpx9VqlTJ9zYB3uDGhhX03bB2drjpcFqG+o1drH//tEGZWdmubhoAFNxZS+3atdO3336rUqVK2SMJTu/me/LkSV1zzTX67bfflF9M00qXLq2//vWveuaZZ3Lvm59jfvazzz57WRUZE2YudVYD4KvST2ZpxA/r9fH8nfa6RZQ5q6mpykeEurppAHxYymWeteR0RcZUQkyIMfz8/HLvBwUFKSMjQ/nJzIU5cuSIHbY6U3R0tL788svzfk1ISIj9Dz7zAeDCQoMC9H+31Ne7vZqqeEigHWoyZzXN2sgGegDcn9NBxlQ71qxZc8796dOnKysrS/mpTJkyNpgkJCScdd9cFy1aNF9/FuDrzjfU9Oo0hpoAeFmQeeGFF+wcFbOXzObNm+3ZS23atLHLskeMGJG/jfP3V9++fe08GVOZMcwcmV9++eWCk30B5F1UmZxVTb1jc1Y1vTtzq3q9v1D7ktPpVgDeMUfGWLt2rV599dXcykz9+vX15JNPqk6dOvneQLNiyYQnU/ExVZjU1FQbbsyeNWcObV3pGBuAs32/KsGuajp6IlOligXr9bsbq+NVZekmAIXicv9+5ynIeBKCDJB3Ow6m2Q301sbnbGMwNK66HrmWDfQAePBkXwA+PtQ0ZqH2pzDUBMA9EGQAXHJV00u31tc7vZrYVU2Lth+2ZzX9timRngPgcgQZAJflpoYV7aqmuhXCdSgtQ33HLtJr0zaygR4AlyLIAHBqqOmrIW10b2xVmdl178zcwlATAM8KMh06dCiYlgDwmKGmf9zaQG/3ZKgJgAcGmXXr1qlly5Z68cUXtXNnzpbmAHxPt0YVNZWhJgCeFmTuu+8+zZs3z55G/dBDD6lr166aMGGC0tNZxQD4mmiGmgC42BXvI3PgwAG7o++4cePsbrtmp1+z86+7YB8ZoHB8uzJef/tyldIyslT61AZ6HdhAD4C77SPz+eef5552PXnyZLvL7jvvvGNPqa5UqZLGjh1rT8ieNWtWXtsOwAPd3KiivhveXnXOWNX0+i+blJ3t1XtuAvC0iow5juDqq6/WJ598Yk+7vuOOO2wV5sxJwElJSerSpYsWLVokV6MiAxSu9JNZeum7dfpk4S57fVPDCnrtzkZ2kjAA5Pff70DlYbKvqb689tprdiipWLFi57xm/fr1io+Pd/ZbA/ACJrD887YGalylhJ6eslrfrUrQ3qTjGt27ucqGhbi6eQC8jNNDS7169dLs2bNtFeZ8IcYwlZqRI0fmR/sAeKg7m1fR+PtaKaJIkJbvStKt787Vxn2prm4WAF8PMjExMZd8TceOHXXzzTfntU0AvERsTGlNGdLGrm4yVZnu/5un2RxtAMCVc2Sio6M1YMAAne/LgoKCFBUVpeuvv14lSpSQO2CODOB6R9IydP+EpVq4/bAC/P30ws31cg+iBIAr+fvtdJDp1KmT5s6dqwoVKqhq1ary8/PTrl27dOjQITVv3lwJCQk6cuSIpk2bpiZNmsjVCDKAe8jIzLZzZr5Yusde928bpWdvrGuDDQAU2vLr1q1ba+LEiTa8/P7775ozZ47d4dfsI3Pddddp48aNdoO8xx9/3NlvDcCLBQf669U7GuqJ62rZ67Fzd2jwx0t09ESmq5sGwIM5HWTMkmqz5PrPunfvrhkzZtjPzdJrM+EXAM5kKrhDOtXQyHuaKiTQX79uOKA7R81XfNJxOgpA4QSZrVu32n1i/uzw4cO2GgMAl3JDgwr67C+tVaZ4iNYnpNgVTav3JNNxAJzm9D4y3bp1U7NmzeyOvmbir7Ft2zZ9/PHHuu222+yOvy+//LJCQtgvAsCFmX1mvh7aRgPHLdGGfam68715euPuJrqufnm6DcBlc3qyb1ZWll599VW9/fbbdmKvYSb+Dh8+XI899piOHz9u58u0atXKTv51NSb7Au4tNf2khk1crlkbE+XnJz11XW0N7hBjh6EA+K6Uglq1ZL6x+QUTFhZmPzcu9gNcjSADuL/MrGx7rMG4+TvtdY8WVfTSrfUVFOD06DcAL1Fgq5bM/jBmYq9hvrE7hxgAniEwwF8v3lJfL3SrK7Mae9Li3er74SIlHzvp6qYBcHNOB5kWLVro559/LpjWAPBp/dpG64O+LVQsOEDzth7Sbf+bq52H0lzdLADeFGRq1aql1NTzn5cyePDg/GgTAB8WV7ucvnigjSpGhGpbYppd0bR4x2FXNwuAt6xaatiwod3d99Zbb1XlypUVEBCQ+5zZIA8ArlSdCuH6emhbDfp4iVbuSdY97y/UK3c00G1NKtO5AK5ssm+RIkVUvvz5l0fu379fx44dkzthsi/guY5nZOnRySv045p99nr41TX0SOerWNEE+ICUy5zs63RFJjY2VjNnzjzvc3Fxcc5+OwC4oCLBAXq3V1O9+vNG/W/WVr01Y4u2HzpmjzoIDfqjGgzAdzldkUlLS1OxYsXkKajIAN5h8pLdembKap3Mcqhp1RIa3ae53RkYgHcqsOXXJsTs3r1bzz//vB599FF7b8qUKdq8efOVtRgALuKu5lX08YBWiigSpGW7kuwk4E37z7/wAIDvcDrImAm9ZuWSCS8//fSTvWeOJTDHE/z6668F0UYAsFpXL60pQ9ooqnRR7TlyXN1HztNvmxLpHcCHOR1knnvuORtYVq1apcjISHvvrrvusvNm/vnPfxZEGwEgV0zZ4poypK1aRpdS6olM9f9osSYsyNkRGIDvcTrImCk1rVu3tp+feRZK2bJl7TlMAFDQShYL1vj7Wqp708rKynbo2a/X2CMOzOcAfIvTQcZMujnfhnhm3szBgwfzq10AcFEhgQF67c6GerxrLXv9we/b9ZfxS5R2IpOeA3yI00GmV69e9mTr//73v0pMTNTHH3+sp59+2i7LHjRoUMG0EgDOw1SFh8bV0Du9migk0F/T1x/QnaPmKyH5OP0F+Ainl18bo0eP1ogRI7Rr1y57XbVqVT3zzDNuGWRYfg34huW7jtidgA8ezVBkeIjG9GmhBpUjXN0sAAX89ztPQea0o0eP2o/FixeXuyLIAL5j9+Fjum/cYm3af1RFggL0Ro/G6lrv/DuRA/DRfWTOZALMmSHm8ccfv5JvBwBXpEqpovbAyQ5XldXxk1m6f8JSvf/bNrtIAYB3croiY/aM+fTTT7VixQqbls78crOvTHx8vNwJFRnA92RmZevFqes0/tSy7J4tq+j/bqmvoIAr+rcbAG+oyPTt21fPPvusnR9jllubIHP6AQDuIDDAX/93Sz09362u/P2kiYt2q9/YRUo+ftLVTQOQz5w+NNJUYsxxBKGhoec8Z1YvAYC7rGjq3zZaVUsV1bCJyzV3yyHdPnKuxvZrqaqli7q6eQDyidMVmdq1a583xBh9+vTJjzYBQL65pk6kvri/jSpEhGprYppuHTlXS3YcpocBXw0yPXr00IMPPqh58+Zp+/btdojp9GPAgAEF00oAuAJ1K4brm6Ft1bByhA6nZajX+wv19fK99Cngi5N9/f3/yD5nHlFgvo25drdjCpjsC+C04xlZeuSzFfpp7T57/dA1NfXwtTXP+l0GwMsn+5pdfU0lxjy2bdt21qNly5ZX2m4AKDBFggM08p6mur9jdXv95q+b9dCkFUo/6V7/AANQgJN9X3vtNVWrVu28z40aNcrZbwcAhcrf309PXV9bMWWK6ekpq/XtynjtTTqu0b2bqXTxEN4NwMNc0c6+noChJQAXMm/rQd0/fqlS0jNVpVQRfdi3hWpGhtFhgLcNLUVHRysmJkZz5sw57/OTJ0+2rylalCWNADxHm+plNGVoW1UrXVS7Dx/X7f+bp983H3R1swDkd0UmLi5OM2fOtJ+/+OKLZ02M+/vf/577eevWrTV//ny5EyoyAC7FrGQylZlFOw4rwN9PL91SX71aVaXjAG+pyJwZXKKiouwcmUmTJtnPL/Q6APAUpYoFa/zAlrq9SSVlZTvs3Jl/fr/Ofg7AveXpiALziIyMZAM8AF4jJDBA/7mrkf7a+Sp7/f6c7fbQyWMZma5uGoCLyPMJalRfAHgb83tt2DU19XbPJgoO9Ncv6/brzlHztS853dVNA3Aly68TEhI0fvz4sw6G3Ldv3zn3EhMTL+fbAYBb69aooiqWKKLBHy/R2vgUe0bTxMGxqla6mKubBiAvk33P3M33YtjZF4A32X34mD0125zRVDEiVJMGt+bAScATJ/t27NhR2dnZl3ywsy8Ab1KlVFFbialetpjik9PV8/0FNtwAcB+XFWT+/e9/X9Y3e+ONN660PQDgVsqFheaGGbMDcI/RhBnA44JMixYtLvscJgDwyjAzKFYxhBnAe1YtAYAvKRceqkkmzJTJqcyYYaY9RxhmAlyNIAMAToQZM8wUXaaY9hzJCTMm1ABwHYIMADgh0oSZQbGKOnU+U4/R8xVPmAFchiADAE4qH5FTmTl92KSZAEyYAVyDIAMAeVAhoogmnQozuw4fs8NMCckMMwGFjSADAFcQZswwU9VSRbXz0DH1HL2A4wyAQkaQAYArYI4yMMNMVUoV0Y5Dx+ycGc5mAgoPQQYArlClEmaYqXVumDHDTPtTOGgSKAwEGQDIpzBjhpkqlyyi7QfT7DATYQYoeAQZAMgnlUsWtWHGhJptJsy8v0AHqMwABYogAwD5fNCkWc1kw0ziqTCTyjATUFAIMgBQQGGmYkSotpowM3qBElNP0M+ArwaZbdu2qXv37oqLi1O9evUUGxurJUuWuLpZAHCJMNP6jzDzPmEG8Mkgk5iYqGuuuUYPPfSQZs6cqZUrV6po0aLasmWLq5sGABdVtXRRuzS7QkSothw4ql7vL9DBo1RmAJ8KMq+88opat26tDh062OvAwECNHj069xoA3Fm10sXsBODy4aHaTJgBfC/IfPXVV+eElho1aqhixYouaxMAOCOqTDE7ZyYyPESb9h/VPe8v1CEqM4D3B5m0tDRt375dWVlZuueee9S2bVt17dpVP/744wW/5sSJE0pJSTnrAQDuEWZa2zCzcX+q7hlDmAG8PsgkJSXZj88995yeeOIJzZ07137s1q2bfvnll/N+zcsvv6yIiIjcR5UqVQq51QBwftFlcoaZyoWFaMO+nDBzOC2D7gKugJ/D4XDITe3bt08VKlRQnz59NG7cuNz7Xbp0UXBwsL777rvzVmTM4zRTkTFhJjk5WeHh4YXWdgC4kK2JR+2S7AOpJ1S7fJgNNyWLBdNhwBnM329TkLjU32+3rsiULVtWISEhqlSp0ln3q1WrZoeczse83vwHn/kAAHdSvWxxu5qp7KnKTK8xC3WEygyQJ24dZAICAuy8mISEhLPu79+/X1WrVnVZuwAgX8LMoFiVKR6i9Qkpdpgp6RjDTIBXBRnjySef1DfffKNdu3bZ63Xr1unnn3/W0KFDXd00ALgiNcoV16TBrWyYWUeYAbxvjsxpEyZM0H/+8x8VL15cmZmZevjhh3X33Xfn6xgbALjK5v2pduffg0czVL9SuCbc10olijJnBr4t5TL/fntEkLkSBBkAnmCTCTOjF+hQWoYaVIqwYSaiaJCrmwW4jFdM9gUAX3FVZJg+HRSr0sWCtXpvsnp/uFDJx0+6ulmA2yPIAICbqFU+J8yUKhasVXuS1ecDwgxwKQQZAHC7MNPKhpmVJsx8uEgp6VRmgAshyACAm6ldPlyfDGylkkWDtHJ3kvp8QJgBLoQgAwBuqE4FE2ZibZhZsTtJfT9cpFQqM8A5CDIA4KbqVgzXhIFmKXaQlu9KssNMhBngbAQZAHBj9SqeWopdJCfMmMrM0ROZrm4W4DYIMgDg5upXirBzZkyYWUaYAc5CkAEADwoz4aGBWrrziPpRmQEsggwAeFSYibVhZsnOI+o/dpHSGGaCjyPIAIAHaVA5wk4ADgsN1OIdJswsJszApxFkAMDDNKxcwk4ADgsJ1KIdh9X/o8U6lsEEYPgmggwAeKBGVUpo/MBTYWb7YVuZIczAFxFkAMBDNa5SQh/f19KGmYXbD2vAR4t1PCPL1c0CChVBBgA8WJOqJTXuvpYqHhKoBdsIM/A9BBkA8HBNTZgZkBNm5m87pPvGUZmB7yDIAIAXaFbNhJkWKhYcoHlbD2nQx0uUfpJhJng/ggwAeIlm1UrZyowJM79vOUiYgU8gyACAF2keVUofDWiposEBmrOZMAPvR5ABAC/TwoSZ/n+EmcHjlzLMBK9FkAEAL9QyupTG9muhIkEB+m1Tov5CmIGXIsgAgJdqFVNaY/vnhJnZmxLtpnnr4lNc3SwgXxFkAMCLxcaU1oenKjNmafYNb82xh00u3nHY1U0D8oWfw+FwyIulpKQoIiJCycnJCg8Pd3VzAMAlNu9P1Vsztuj7VfHKPvVbv2VUKT0QV12driorPz8/3hl45N9vggwA+JAdB9P03m9b9eXSvcrIyrb36lYI15C46rq+fgUF+BNo4B4IMk52BAD4kn3J6RozZ5s+XbRLx06dzxRdppju7xij25pUVnAgMw/gWgQZJzsCAHzRkbQMjZu/Q2Pn7lDy8ZP2XvnwUA1sH61eraqqaHCgq5sIH5XC0JJzHQEAviztRKYmLtql9+ds0/6UE/ZeyaJB6tcmWn3bVFOJosGubiJ8TApBxrmOAABIJzKz9NWyvXpv9lbtOHTMdok58sBUZwa2j1FkeCjdhEJBkHGyIwAAf8jKduiH1QkaOWur1ifk7D0THOCv7s0q23k01UoXo7tQoAgyTnYEAOBcZoeOWRsTNXLWFi3eccTeMwubbmpYUQ90qq46Ffi9ioJBkHGyIwAAF7do+2EbaEywOe3q2uU0NK66PXkbyE8EGSc7AgBwedbsTdb/Zm+1Q0+nt1Q1ZzsNjauhDjXLsLke8gVBxsmOAAA4Z7vZXG/2Vn25bI9OZuUkmnoVwzWkUw1dV788m+vhihBknOwIAEDeJCQf15g52/Xpwl06fjJnc70Yu7ledd3apBKb6yFPCDJOdgQA4MocTsvQR/N2aNy8PzbXqxBhNteLUc+WVdhcD04hyDjZEQCA/HHUbK63MGdzvQOpf2yu179ttPq2jlJE0SC6GpdEkHGyIwAA+Sv9ZM7meqNmb9Wuw39srndvbDXd1y5a5dhcDxdBkHGyIwAABSMzK1vfr07Q/2Zt1YZ9qfaeOZTyDrO5Xofqqlq6KF2PcxBknOwIAEDBb643c+MBvTtzq5bu/GNzvW6NcjbXq12e39H4A0HGyY4AABReoMnZXG+rZm/6Y3O9a+uU0wOdaqhZtZK8FRBB5hSCDAC4+eZ6s7bqhzV/bK4XG1PK7kXTns31fFoKp1871xEAANfZmnjUbq43Zfne3M31GlSK0JBO1dW1Xnn5mzEo+JQUgoxzHQEAcL34pJzN9SYuOmNzvbKnNtdrzOZ6viSFIONcRwAA3Gxzvbnb7QZ7KemZ9l7FiFAN6hCjHi2qqkhwgKubiAJGkHGyIwAA7ic1/aQ9+mDM79uVeGpzvVLFgjW4Q4x6x1ZTsZBAVzcRBYQg42RHAADce3O9L5bu0Xu/bdXuw8ftPQKNdyPIONkRAADP2Fzv6xXxenvGZu08dCw30AxqH6M+ranQeBOCjJMdAQDwrEDzzalAs+NUoDHnOZk5NH1aR6k4Q04ejyDjZEcAADwPgcZ7EWSc7AgAgGcHmm9XmgrNFm0/mGbvlTAVmvYx6tuGCo0nIsg42REAAO8INFNXxeutX88NNGYOTVhokKubiMtEkHGyIwAA3hdo3v51i7YRaDwSQcbJjgAAeJ+sbIemrjQVms25gSaiiKnQRNshJyo07osg42RHAAB8INDM2KxtiX8EmoHtotWvLYHGHRFknOwIAIBvBJrvVsXrzV/PDTR920YpnDk0boMg42RHAAB8L9CYIaetpwJNeGigBraPsRUaAo3rEWSc7AgAgO8GGrNse8uBo7mB5r52MerfjkDjSgQZJzsCAODbgeb71Qm2QvPnQGMqNGb4CYWLIONkRwAAYALND6sT7Bya04EmzAaaaPVvG02gKUQEGSc7AgCAPwcaU6HZfEagGdA2WgPaEWgKA0HGyY4AAODPsk2gWZOgN6cTaAobQcbJjgAA4GKB5sc1+/Tmr5u0af+pCk1IoPq3i9Z9ZsipKHNo8htBxsmOAADgUgg0hYcg42RHAADgTKD5ae0+O+S0cX/qHxWatlF2Dk2JosF05hUiyDjZEQAA5CXQTDOB5tfN2rAvJ9AUPxVozEonAk3eEWSc7AgAAPKKQJP/CDJOdgQAAPkRaH5et09vTD+7QtOvTU6FpmQxhpwuF0HGyY4AAKAgA02x4AC7S/DAdjEEmnz8++0vD/LOO+/Iz89Ps2bNcnVTAAC4IH9/P11Xv4J+GN5eo+5tpjoVwpWWkaV3Z25Vu1dm6NVpG3QkLYMezAceE2Ti4+P16quvuroZAAA4GWjK6/th7fRe73MDzYgf1utASjo96gtBZtiwYXr66add3QwAAPIUaLrW+yPQ1D0VaEb/tk3t/j1Tz369WrsPH6Nn8yBQHmDq1KkKCgpS165dL/naEydO2MeZY2wAALhToOlSN1IzNx7QOzO2aNmuJE1YsEsTF+3WLY0q6oFO1VUzMszVTfUYbl+RSUtL0zPPPKPXX3/9sl7/8ssv28lBpx9VqlQp8DYCAOAMM9/z6tqR+vKBNpo0OFbta5axB1V+tXyvOr/+m/4yfolW7UmiUy+Dn8PhcMiNPfroo6pRo4aGDBmiHTt2KDo6WjNnzlSnTp0uuyJjwgyrlgAA7mzl7iSNnLVF09buz71nAs7QuBpqFV3Khh9fknKZq5bcemhp2bJlWrhwoV577bXL/pqQkBD7AADAkzSqUkLv9W6uTftTNWrWVn2zMl5zNh+0j2bVSmpoXHXF1Srnc4HGoysyL730kqZMmZKbxNLT022wadSokUqUKKExY8bYas3FsI8MAMATmcm/7/22VZOX7FFGZra9Z1Y9DelUXTc0qKAAf+8ONF65Id7lDC39GUEGAODJzPLsMb9v14QFO3UsI8veiy5TTPd3jNFtTSorONDtp7vmiVduiAcAgK8pFx6qp2+oo3lPXa2Hr62piCJB2n4wTU9+uVodX52psXO36/ipgOOLPKYi8/DDD2vBggW5Q0u1a9fWpEmTLvl1VGQAAN7k6IlMTVy4S+/P2aYDqTmLW0oVC7ZnOd0bW80GHW/glUNLeUGQAQB4o/STWfpy2R6Nmr1Vuw8ft/fCQgLVu3U1DWgXrTLFPXvhC0HGyY4AAMATZWZla+qqeI2cuVWbDxy190KD/NWjRVUN7hCjiiWKyBMRZJzsCAAAPP3E7V/W79e7M7do1Z5key/Q30+3N62k+ztWV0zZ4vIkBBknOwIAAG/gcDg0d8shG2jmbztk75mtZ8ySbbN0u17FCHkCgoyTHQEAgLdZuvOI/jdri6avP5B7L65WWbtbcPOoUnJnBBknOwIAAG+1PiFFI2dt1fer4pV9aolPy+hSNtB0qFnGLXcLJsg42REAAHi77QfT9N7srXa108msnETToFKEPf6gS93y9nRud0GQcbIjAADwFQnJx/X+b9v16aKdSj+Zc/xBjXLF9UDH6rq5cUUFBbh+v1yCjJMdAQCArzl09IQ+mrfDPlLTM+29SiWK2OMP7mxeRaFBAS5rG0HGyY4AAMBXpaSftGc5fTBnuw6lZdh7ZkO9ge1zdgsuHhJY+G1iZ1/nOgIAAF93PCNLk5fstvNo4pPT7b3w0ED1axut/m2iVLJYcKG1hSDjZEcAAIAcGZnZ+mbFXv1v1lZtO5hm7xUNDlCvllU1sH2MykeEqqARZJzsCAAAcLasbIemrd1nN9dbG59i7wUH+Kt7s8p2Hk210sVUUAgyTnYEAAC48G7Bszcl2kCzeMcRe8+s1O7WqKKGdKqhWuXDlN8IMk52BAAAuLRF2w/bQGOCzWmPdblKD15dU674+13405ABAIDHahldSi2jW2rN3mSNnLVFP67Zp1YxpV3WHoIMAABwWv1KERp5TzPtPnxMVUoVlau4fus+AADgsaq4MMQYBBkAAOCxCDIAAMBjEWQAAIDHIsgAAACPRZABAAAeiyADAAA8FkEGAAB4LIIMAADwWAQZAADgsQgyAADAYxFkAACAxyLIAAAAj0WQAQAAHitQXs7hcNiPKSkprm4KAAC4TKf/bp/+O+6zQSY1NdV+rFKliqubAgAA8vB3PCIi4oLP+zkuFXU8XHZ2tuLj4xUWFiY/P798TYomHO3evVvh4eH59n2Rd7wn7oX3w73wfrgX3o9LM/HEhJiKFSvK39/fdysy5j++cuXKBfb9TYghyLgX3hP3wvvhXng/3Avvx8VdrBJzGpN9AQCAxyLIAAAAj0WQyaOQkBA9//zz9iPcA++Je+H9cC+8H+6F9yP/eP1kXwAA4L2oyAAAAI9FkAEAAB6LIAMAADwWQSaPpkyZohYtWqh9+/bq2LGj1q5dm7/vDC7b5MmT1aVLF11zzTX2Pbnzzju1Y8cOetANvPPOO3YjylmzZrm6KT5v27Zt6t69u+Li4lSvXj3FxsZqyZIlPt8vrnDixAk98sgjatSokf370apVK/s3BXlkJvvCOQsXLnSEhYU5Nm3aZK/HjRvnqFSpkiMlJYWudIGgoCDHTz/9ZD/Pyspy9O7d21GrVi1Heno674cL7d2711G1alWzmMAxc+ZM3gsXOnDggCMqKsoxe/Zse33y5ElHXFycY+LEibwvLvDss8/a9yMpKcleL1u2zBEcHOxYsWIF70ceUJHJg3/961+68cYbVbNmTXt97733KjMzUx999FFe8ySuwC233KKuXbvm7uQ8fPhwbdy4UcuWLaNfXWjYsGF6+umneQ/cwCuvvKLWrVurQ4cO9jowMFCjR4/OvUbhWrFiha0en961tkmTJvbzGTNm8FbkAUEmD3799Vc1b978j07091ezZs00ffr0vHw7XKHPP//8rOvQ0NDc8i1cY+rUqQoKCsoNmHCtr7766pzQUqNGDXuGDQqfGeKbM2eOdu3aZa+nTZumxMRERUZG8nbkgdeftZTfDh06ZA/7+vP/cOXLl9fixYtd1i78Yf78+fYXdNu2bekWF0hLS9MzzzxjfzkTJt3j/di+fbuysrJ0zz332PljxYsX18MPP6zrr7/e1c3zSf369dOxY8fUsGFDVahQQZs2bdIdd9yhu+66y9VN80gEGSeZ//mMP+/oa65PPwfXMX84X331VTvJ1FQEUPiee+453X///fYXNJOuXS8pKSn3fZk5c6adYGqqyqZa9uOPP6pz586ubqLPGTNmjJ2isHTpUlWvXl0rV660Ff2LnfCMC6PXnFS0aFH78c//0jTXp5+D6/zlL3/R3Xffrdtuu423wQXMvKSFCxfaIAP3EBAQYD9269bNhhjDrPC7+uqr9eabb7q4db7HbKb/xBNP2N9VJsQY5n354YcfNGLECFc3zyMRZJxUunRpOylr//79Z93ft2+fYmJi8vO9gZOeeuopGyZfeukl+s5Fvv/+ex0/ftz+kezUqZN69Ohh75thDHO9ZcsW3ptCVrZsWVsxrlSp0ln3q1WrZoecULjMXJgjR44oKirqrPvR0dH68ssveTvygKGlPDC/pE1J8MyEbf4lauYFwDVMmXb37t0aP368vT79/phJ2Cg8ZvjCPE4zQ0vmF/Qbb7xhgwxcU5Ex88USEhLOum/+MVa1alXekkJWpkwZGyz//H6Ya6r6eUNFJo//8jf/8jz9r8tPPvnE/rLo27dvHt8GXIlRo0ZpwoQJdrmvCZRmky+zamb16tV0LCDpySef1DfffJO7SmbdunX6+eefNXToUPqnkJl5MOZvhZknYyozhvm99csvvzDZN484/TqPzC6M//znP1WkSBH7P+bIkSPtbpkoXKmpqSpRooSys7PPeW7s2LF2dQBcwwwnLViwwM6ZMXMAateurUmTJvF2uIgJ+//5z3/siiWz75V5f8x8MhQ+szDkhRdesBN8TRXG/B4z4cbs9mt2woZzCDIAAMBjMbQEAAA8FkEGAAB4LIIMAADwWAQZAADgsQgyAADAYxFkAACAxyLIAAAAj0WQAQAAHosgAyBfLFq0yJ6nZHYmNbv4/t///Z+SkpLsDqbmY2Ex5zuZn/lnt956q15//fVCaweAwsHOvgDy95eKn1/u8RCnD400pyz/+bTfgjJr1izFxcXZw1zPZLZ/b9mypXr27Fko7QBQODj9GoBPoBoDeCeGlgAUCHPCco8ePezn5qMZdjKHrRpHjx7VoEGD1KRJE3Xs2NEO+5w+mfn3339XbGysrex8/vnnuuWWW1SjRg01btzYPm8OaG3VqpWturRo0cIe3nq6+jJjxgx7GKJhfp55zJ8/X0888YStCJnrM40fP95+X/P9TFvMzztt4MCBKl++vPr06WNPjzbtrFWrlqZNm8b/MYA7cQBAPjK/VsaOHWs/3759u702H8/Us2dP+8jKyrLXI0aMcNStW9eRmZl51tcNGDDAviY1NdXRqVMn+1yLFi0cq1evtp8fPXrU0bBhQ8e4ceNyv/fMmTPt1/7Z888/7+jYsWPu9bRp0xzFixd3bNiwwV6vWrXKERoa6pg7d27ua/r27esoWbKkY/369fb6zTffdFStWjUfewvAlaIiA6BQbdu2TZMmTdKjjz4qf/+cX0GDBw+2FRwzv+VMphpiXlO8eHHNnDnT3jNVk/r169vPixUrphtuuEE//vij0+0wlRxTCTJVFqNBgwbq2rWrRowYcdbrTKXGTF42TEXHVI6OHDmSx/96APmNOTIACtXatWvtUNBDDz2koKCg3PvVqlVTYmLiWa+tXLnyOV+/Z88eDR8+XAcPHrRff3pCsbPWrFmjq6+++qx7ZgjrzOElo2LFirmfh4WF2Y8pKSkqWbKk0z8TQP4jyABwiQkTJlwygAQEBJx1vXPnTnXu3Nku7X7sscfsPbPU+s+VnPx0ZhvMvB3jzyuiALgOQ0sACu4XzKmhIyM7O1tpaWmqV6+evd64ceNZr/373/+uDRs2XPT7LVmyRMePH9fdd9+dey8jI+OCPzMzM9O+/nzM8NSWLVvOurd161Y7xATAcxBkABSY0qVL22Bh5pSYEGL2lomJibF7ufz73/9Wenq6fd28efP05Zdf2qGdizFzVUxV5Ndff7XXJqT8eX5M2bJl7UfzM7/66isbkM7nmWee0TfffKPNmzfnDnn99NNPevrpp/Plvx1AIbni6cIA4HA4Fi5caFcFmV8rtWrVcrz44ou2X5544glHvXr1HK1atXL8/vvv9p5ZhTR48GD7OrMaqVu3bo7Nmzfb55YvX25fa76P+fj222+f1b+jRo1yREVFOdq3b++44447HN27d3dEREQ4evXqlfsa83njxo0drVu3tquSHn/8cUe1atXs62688cbc15nVTo0aNXK0bNnSvv6zzz7Lfe6hhx5yREZG2of5evN9zmyXWeUEwPXY2RcAAHgshpYAAIDHIsgAAACPRZABAAAeiyADAAA8FkEGAAB4LIIMAADwWAQZAADgsQgyAADAYxFkAACAxyLIAAAAj0WQAQAA8lT/D6CpsTeSM6wRAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(abs(np.array(adapt_energies) - exact_energy))\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Energy error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68f30093",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_errors = np.abs(np.array(adapt_energies) - exact_energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d965f4a6",
   "metadata": {},
   "source": [
    "## Carry out SQD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0a71f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "\n",
    "spin_a_layout = list(range(0, 12))\n",
    "spin_b_layout = [12, 13, 14, 15, 19, 35, 34, 33, 32, 31, 30, 29]\n",
    "initial_layout = spin_a_layout + spin_b_layout\n",
    "\n",
    "pass_manager = generate_preset_pass_manager(\n",
    "    optimization_level=3, backend=computer, initial_layout=initial_layout[:nq]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbb1145f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gate counts (w/ pre-init passes): OrderedDict({'measure': 16, 'x': 8, 'cx': 6, 'rz': 3, 'sx': 2, 'barrier': 2})\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'measure': 16, 'cx': 14, 'rz': 12, 'sx': 8, 'x': 8, 'barrier': 3})\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'cx': 24, 'rz': 21, 'measure': 16, 'sx': 12, 'x': 9, 'barrier': 4})\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'cx': 31, 'rz': 26, 'measure': 16, 'sx': 14, 'x': 9, 'barrier': 5})\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'cx': 38, 'rz': 36, 'sx': 18, 'measure': 16, 'x': 10, 'barrier': 6})\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'cx': 45, 'rz': 41, 'sx': 22, 'measure': 16, 'x': 10, 'barrier': 7})\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 54, 'cx': 52, 'sx': 28, 'measure': 16, 'x': 11, 'barrier': 8})\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 63, 'cx': 58, 'sx': 32, 'measure': 16, 'x': 11, 'barrier': 9})\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 71, 'cx': 62, 'sx': 38, 'measure': 16, 'x': 11, 'barrier': 10})\n",
      "Gate counts (w/ pre-init passes): OrderedDict({'rz': 83, 'cx': 68, 'sx': 46, 'measure': 16, 'x': 11, 'barrier': 11})\n"
     ]
    }
   ],
   "source": [
    "bit_arrays = []\n",
    "counts_list = []\n",
    "for circuit in circuits:\n",
    "    pass_manager.pre_init = ffsim.qiskit.PRE_INIT\n",
    "    to_run = pass_manager.run(circuit)\n",
    "    print(f\"Gate counts (w/ pre-init passes): {to_run.count_ops()}\")\n",
    "    job = sampler.run([to_run], shots=30_000)\n",
    "    bit_array = job.result()[0].data.meas\n",
    "    counts1 = bit_array.get_counts()\n",
    "    counts_list.append(counts1)\n",
    "    bit_arrays.append(deepcopy(bit_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77f6310a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "(30000, 16)\n",
      "16\n",
      "(30000, 16)\n",
      "16\n",
      "(30000, 16)\n",
      "16\n",
      "(30000, 16)\n",
      "16\n",
      "(30000, 16)\n",
      "16\n",
      "(30000, 16)\n",
      "16\n",
      "(30000, 16)\n",
      "16\n",
      "(30000, 16)\n",
      "16\n",
      "(30000, 16)\n",
      "16\n",
      "(30000, 16)\n"
     ]
    }
   ],
   "source": [
    "energies = []\n",
    "errors = []\n",
    "\n",
    "for bit_array in bit_arrays:\n",
    "    print(bit_array.num_bits)\n",
    "    bit_matrix = bit_array.to_bool_array()\n",
    "    print(bit_matrix.shape)\n",
    "    eigvals, eigvecs = solve_qubit(bit_matrix, h_qiskit)\n",
    "    min_energy = np.min(eigvals)\n",
    "    err = abs(min_energy - exact_energy)\n",
    "    energies.append(min_energy)\n",
    "    errors.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8500129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Energy error')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(errors)\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Energy error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01421e02",
   "metadata": {},
   "source": [
    "## Concatenate mulitple rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2e3f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_energies = []\n",
    "stacked_errors = []\n",
    "\n",
    "for i in range(1, len(counts_list) + 1):\n",
    "    all_counts = collections.Counter()\n",
    "    tuple_of_counts = tuple(counts_list[:i])\n",
    "    assert len(tuple_of_counts) == i\n",
    "    for counts in tuple_of_counts:\n",
    "        for bitstring, count in counts.items():\n",
    "            all_counts[bitstring] += count\n",
    "\n",
    "    bit_array = qiskit.primitives.BitArray.from_counts(all_counts)\n",
    "    bit_matrix = bit_array.to_bool_array()\n",
    "    eigvals, eigvecs = solve_qubit(bit_matrix, h_qiskit)\n",
    "    min_energy = np.min(eigvals)\n",
    "    err = abs(min_energy - exact_energy)\n",
    "    stacked_energies.append(min_energy)\n",
    "    stacked_errors.append(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6263d499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Energy error')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(stacked_errors)\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Energy error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb9a1bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1285a6a50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adapt_rel_errors = adapt_errors / abs(exact_energy)\n",
    "rel_errors = np.array(errors) / abs(exact_energy)\n",
    "stacked_rel_errors = np.array(stacked_errors) / abs(exact_energy)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(adapt_rel_errors, '.', label=\"ADAPT\")\n",
    "ax.plot(rel_errors, '.', label=\"Separate\")\n",
    "ax.plot(stacked_rel_errors, '.', label=\"Stacked\")\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Energy error\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16e09f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adapt",
   "language": "python",
   "name": "adapt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
